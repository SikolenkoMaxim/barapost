#!/usr/bin/env python3
# -*- coding: utf-8 -*-

__version__ = "3.4.b"
# Year, month, day
__last_update_date__ = "2019-11-19"

# |===== Check python interpreter version =====|

import sys

if sys.version_info.major < 3:
    print( "\nYour python interpreter version is " + "%d.%d" % (sys.version_info.major, sys.version_info.minor) )
    print("   Please, use Python 3!\a")
    # In python 2 'raw_input' does the same thing as 'input' in python 3.
    # Neither does 'input' in python2.
    raw_input("Press ENTER to exit:")
    exit(1)
# end if


def platf_depend_exit(exit_code):
    """
    A function that asks to press ENTER on Windows
        and exits.

    :type exit_code: int;
    """
    if sys.platform.startswith("win"):
        input("Press ENTER to exit:")
    # end if
    exit(exit_code)
# end def platf_depend_exit


# Firstly search for information-providing options:

if "-h" in sys.argv[1:] or "--help" in sys.argv[1:]:
    print("\n  fastQA5-sorter.py\n  Version {}; {} edition;\n".format(__version__, __last_update_date__))
    print("DESCRIPTION:\n")
    print("""fastQA5-sorter.py -- this script is designed for sorting (dividing into separate files)
    FASTQ and FASTA files processed by "barapost.py".""")

    if "--help" in sys.argv[1:]:
        print("""Moreover, it can sort FAST5 files according to taxonomical annotation of FASTQ files,
    that are result of basecalling these FAST5 files. For details, see README.md
    on github page ('FAST5 sorting' section): https://github.com/masikol/barapost\n
"fastQA5-sorter.py" is meant to be used just after "barapost.py".""")
        print("""----------------------------------------------------------\n
Default parameters:\n
- all FASTQ, FASTA and FAST5 files in current directory will be processed;
- sorting sensitivity (see '-s' option): 'genus';
- output directory ('-o' option): directory named '"fastQA5_sorter_result_<date_and_time_of_run>"''
  nested in current directory;
- minimum mean quality of a read to keep ('-q' option): 20 (Phred33);
- length filtering ('-m' option) is disabled;
- "FAST5 untwisting" is disaled by default;""")
    # end if

    print("----------------------------------------------------------\n")
    print("""Files that you want 'fastQA5-sorter.py' to process should be
    specified as positional arguments (see EXAMPLE #2 running detailed (--help) help message).
Wildcards do work: './fastQA5-sorter.py my_directory/*' will process all files in 'my_directory'.\n""")
    print("OPTIONS:\n")
    print("""-h (--help) --- show help message.
        '-h' -- brief, '--help' -- full;\n""")
    print("-v (--version) --- show version;\n")
    print("""-r (--taxannot-resdir) --- result directory genearted by script 'prober.py'
        This is directory specified to 'prober.py' by '-o' option.
        Default value is "barapost_result", since it is the default name of
        output directory generated by "prober.py".\n""")
    print("""-d (--indir) --- directory which contains FAST(Q/A/5) files
        (FASTQ and FASTA files can be gzipped) meant to be sorted;\n""")
    print("-o (--outdir) --- output directory;\n")
    print("""-s (--sorting-sensitivity) --- sorting sensitivity,
        i.e. the lowest taxonomy rank that will be used in names of resut files;
        Available values: 'genus', 'species', 'strain'; Default is 'genus'.\n""")
    print("""-q (--min-ph33-qual) --- minimum mean Phred33 quality of a read to keep;
        Reads of lower quality will be written to separate "trash" file;
        Default value: 20;\n""")
    print("""-m (--min-seq-len) --- minimum length of a sequence to keep.
        Shorter sequences will be written to separate "trash" file.
        Length filtering is disabled by default;\n""")
    print("""-u (--untwist-fast5) --- flag option. If specified, FAST5 files will be
        sorted considering that they and "corresponding" FASTQ files contain
        different reads (like after basecalling performed by Guppy).
        Disabled by default;\n""")
    print("""-z (--gzip) --- Compress output files with gzip.
        Compression affects only FASTA and FASTQ files;
        Values: 'true', 'false' (see Example #2).
        'true' by default.""")

    if "--help" in sys.argv[1:]:
        print("----------------------------------------------------------\n")
        print("EXAMPLES:\n")
        print("""  1. Process all FASTA and FASTQ files in working directory with default settings:\n
  ./fastQA5-sorter.py\n""")
        print("""  2. Process all files in the working directory that start with "some_my_fastq".
  Ignore reads with mean Phred33 quality < 15. Do not compress output files.
  The rest of settings are default:\n
  ./fastQA5-sorter.py some_my_fastq* -q 15 -z false\n""")
        print("""  3. Process one FASTQ file with default settings.
  File 'reads.fastq' has been already processed by "barapost.py".
  Results of "barapost.py" work are in directory 'prober_outdir':\n
  ./fastQA5-sorter.py reads.fastq.gz -r prober_outdir/\n""")
        print("""  4. Process a FASTQ file and a FASTA file, place results in 'outdir' directory.
  Files 'reads.fastq.gz' and 'another_sequences.fasta' have been already processed by "barapost.py".
  Results of "barapost.py" work are in directory 'prober_outdir':\n
  ./fastQA5-sorter.py reads_1.fastq.gz some_sequences_2.fasta -o outdir -r prober_outdir/\n""")
        print("""  5. Process all FASTQ and FASTA files in directory named 'dir_with_seqs'. Sort by species.
  All these files have been already processed by "barapost.py". Perform "FAST5 untwisting".
  Results of "barapost.py" work are in directory 'prober_outdir':\n
  ./fastQA5-sorter.py -d dir_with_seqs -o outdir -r prober_outdir/ -s species -u""")
        # end if
    platf_depend_exit(0)
# end if

if "-v" in sys.argv[1:] or "--version" in sys.argv[1:]:
    print(__version__)
    platf_depend_exit(0)
# end if


def err_fmt(text):
    """Function for configuring error messages"""
    return "\n  \a!! - ERROR: " + text + '\n'
# end def print_error

from time import time, strftime, localtime, sleep, gmtime

start_time = time()

def getwt():
    return strftime("%H:%M:%S", gmtime( time() - start_time ))
# end def get_work_time

# Get start time
from datetime import datetime
now = datetime.now().strftime("%Y-%m-%d %H.%M.%S")
# -------------------

from gzip import open as open_as_gzip
from re import search as re_search
from glob import glob
import os
import getopt

try:
    opts, args = getopt.gnu_getopt(sys.argv[1:], "hvr:d:o:s:q:m:ut:z:",
        ["help", "version", "taxannot-resdir=", "indir=", "outdir=",
         "sorting-sensitivity=", "min-ph33-qual=", "min-seq-len=",
         "untwist-fast5", "threads=", "gzip="])
except getopt.GetoptError as gerr:
    print( str(gerr) )
    platf_depend_exit(2)
# end try

is_fastQA5 = lambda f: True if not re_search(r".*\.(m)?f(ast)?(a|q|5)(\.gz)?$", f) is None else False
is_fastqa = lambda f: False if re_search(r"\.(m)?f(ast)?(q|a)(\.gz)?$", f) is None else True
is_fast5 = lambda f: f.endswith(".fast5")

# |== Default parameters: ==|
fq_fa_list = list() # input FASTQ and FASTA files paths
fast5_list = list() # input FAST5 files paths
tax_annot_res_dir = "barapost_result" # path to result TSV file generated by barapost.py
indir_path = None # path to input directory
outdir_path = "fastQA5_sorter_result_{}".format(now.replace(' ', '_')) # path to output directory
sens = "genus" # sorting sensitivity
min_ph33_qual = 20 # minimum mean read quality to keep
min_qlen = None # minimum seqeunce length to keep (unlimited by delault, see 'SeqLength' class definition)
untwist_fast5 = False # flag indicating whether to run 'FAST5-untwisting' or not
n_thr = 1 # number of threads to launch
compress = True # flag indicating whether to compress output files or not

# Add positional arguments to fq_fa_list and fast5_list
for arg in args:
    if not os.path.exists(arg):
        print(err_fmt("file does not exist:\n '{}'".format(os.path.abspath(arg))))
        platf_depend_exit(1)
    # end if
    if is_fastqa(arg):
        fq_fa_list.append( os.path.abspath(arg) )
    elif is_fast5(arg):
        fast5_list.append( os.path.abspath(arg) )
    else:
        print(err_fmt("invalid positional argument: '{}'".format(arg)))
        print("Only FAST(A/Q/5) files can be specified without a key in command line.")
        platf_depend_exit(1)
    # end if
    
# end for

# Import 'multiprocessing' only if there is a '-t' ('--threads') option in command line:
if "-t" in sys.argv[1:] or "--threads" in sys.argv[1:]:
    import multiprocessing as mp
# end if

for opt, arg in opts:

    if opt in ("-o", "--outdir"):
        outdir_path = os.path.abspath(arg)

    elif opt in ("-r", "--taxannot-resdir"):
        if not os.path.exists(arg):
            print(err_fmt("directory '{}' does not exist!".format(arg)))
            platf_depend_exit(1)
        # end if
        if not os.path.isdir(arg):
            print(err_fmt("'{}' is not a directory!".format(arg)))
            platf_depend_exit(1)
        # end if
        tax_annot_res_dir = os.path.abspath(arg)

    elif opt in ("-s", "--sorting-sensitivity"):
        if arg not in ("genus", "species", "strain"):
            print(err_fmt("invalid value specified with '-s' option!\n"))
            print("Available values: 'genus', 'species', 'strain'")
            print("\nType for help:\n    ./fastQA5-sorter.py -h")
            platf_depend_exit(1)
        # end if
        sens = arg

    elif opt in ("-q", "--min-ph33-qual"):
        try:
            min_ph33_qual = float(arg)
            if min_ph33_qual < 0:
                raise ValueError
            # end if
        except ValueError:
            print(err_fmt("min Phred33 quality must be positive number!"))
            print("You've specified '{}'".format(arg))
            platf_depend_exit(1)
        # end try

    elif opt in ("-m", "--min-seq-len"):
        try:
            min_qlen = int(arg)
            if min_qlen < 0:
                raise ValueError
            # end if
        except ValueError:
            print(err_fmt("minimum length of the sequence must be positive integer number!"))
            print("You've specified '{}'".format(arg))
            platf_depend_exit(1)
        # end try

    elif opt in ("-u", "--untwist-fast5"):
        untwist_fast5 = True

    elif opt in ("-z", "--gzip"):
        if arg in ("true", "false"):
            compress = False if arg == "false" else True
        else:
            print(err_fmt("invalid value passed with '{}' option".format(opt)))
            print("Available values: 'true', 'false'")
            print("You have specified '{}'".format(arg))
            platf_depend_exit(1)
        # end if

    elif opt in ("-t", "--threasds"):
        try:
            n_thr = int(arg)
            if n_thr < 1:
                raise ValueError
            # end if
        except ValueError:
            print(err_fmt("number of threads must be positive integer number!"))
            platf_depend_exit(1)
        # end try
        if n_thr > mp.cpu_count():
            print("""\nWarning! You have specified {} threads to use
  although {} are available.""".format(n_thr, mp.cpu_count()))
            error = True
            while error:
                reply = input("""\nPress ENTER to switch to {} threads,
  or enter 'c' to continue with {} threads,
  or enter 'q' to exit:>>""".format(mp.cpu_count(), n_thr))
                if reply in ("", 'c', 'q'):
                    error = False
                    if reply == "":
                        n_thr = mp.cpu_count()
                        print("\nNumber of threads switched to {}\n".format(n_thr))
                    elif reply == 'c':
                        pass
                    elif reply == 'q':
                        exit(0)
                    # end if
                else:
                    print("\nInvalid reply!\n")
                # end if
            # end while
        # end if

    elif opt in ("-d", "--indir"):
        if not os.path.exists(arg):
            print(err_fmt("directory '{}' does not exist!".format(arg)))
            platf_depend_exit(1)
        # end if
        
        if not os.path.isdir(arg):
            print(err_fmt("'{}' is not a directory!".format(arg)))
            platf_depend_exit(1)
        # end if
        indir_path = os.path.abspath(arg)

        fq_fa_list.extend(list( filter(is_fastqa, glob("{}{}*".format(indir_path, os.sep))) ))
        fast5_list.extend(list( filter(is_fast5, glob("{}{}*".format(indir_path, os.sep))) ))
    # end if
# end for

# Check if "prober result" directory is specified
if not os.path.exists(tax_annot_res_dir):
    print(err_fmt("directory '{}' does not exist!".format(tax_annot_res_dir)))
    if tax_annot_res_dir == "barapost_result":
        print("""Maybe, output directory generated by 'prober.py' hasn't been named 'barapost_result'
    and you have forgotten to specify '-r' option.""")
    platf_depend_exit(1)
    # end if
# end if

# If no FAST(A/Q/5) file have been specified
if len(fq_fa_list) == 0 and len(fast5_list) == 0:
    # If input directory was specified -- exit
    if not indir_path is None:
        print(err_fmt("no input FAST(Q/A/5) files found: there is no FAST(Q/A/5) files in the input directory.\n"))
        print("Input directory: '{}'".format(indir_path))
        platf_depend_exit(1)
    # If input directory was not specified -- look for FASTQ and FASTA files in current directory
    else:
        fq_fa_list.extend(list( filter(is_fastqa, glob("{}{}*".format(os.getcwd(), os.sep))) ))
        fast5_list.extend(list( filter(is_fast5, glob("{}{}*".format(os.getcwd(), os.sep))) ))
        if len(fq_fa_list) == 0 and len(fast5_list) == 0:
            print(err_fmt("no input FAST(Q/A/5) files are specified and there is no FAST(Q/A/5) file in working directory.\n"))
            platf_depend_exit(1)
        # end if
    # end if
# end if

if len(fast5_list) == 0 and untwist_fast5:
    print("\nWarning! No FAST5 file has been given to sorter's input.")
    print("Therefore, '-u' ('--untwist-fast5') flag does not make any sense.")
    print("Ignoring it.")
    untwist_fast5 = False
# end if

# Sort input files in order to process them in alphabetical order
fq_fa_list.sort()
fast5_list.sort()

# Create output directory
if not os.path.isdir(outdir_path):
    try:
        os.makedirs(outdir_path)
    except OSError as oserr:
        print(err_fmt("unable to create result directory"))
        print("fastQA5-sorter just tried to create directory '{}' and crushed.".format(outdir_path))
        print("Reason: {}".format( str(oserr) ))
        platf_depend_exit(1)
    # end try
# end if


def get_checkstr(fast5_fpath):
    """
    Function returns string that will help fasQA5-sorter to find
        TSV file generated by prober and barapost while provessing FASTQ file
        that in turn is basecalled 'fast5_fpath'-file.
    
    Function first searches for ID given to file by programs like of MinKNOW.
    That is:
        1) sequence of 40 (I've seen 40, maybe there can be other number)
        latin letters in lower case interlaced with numbers;
        2) underscore;
        3) number of file within sequenator run;
    For example: file named "FAK94973_e6f2851ddd414655574208c18f2f51e590bf4b27_0.fast5"
        has checkstring "e6f2851ddd414655574208c18f2f51e590bf4b27_0".
    "FAK94973" is not regarding because it can be pruned by basecaller. For example, Guppy acts in this way.

    If no such distinctive string is found in FAST5 file name
        (file can be renamed by the user after sequensing)
        whole file name (except of the '.fast5' extention) is returned as checksting.

    :param fast5_fpath: path to FAST5 file meant to be processed;
    :type fast5_fpath: str;

    Returns checkstring described above.
    """

    try:
        # I'll lower the 40-character barrier down to 30 just in case.
        filename_payload = re_search(r"([a-zA-Z0-9]{30,}_[0-9]+)", fast5_fpath).group(1)
    except AttributeError:
        return os.path.basename(fast5_fpath).replace(".fast5", "")
    else:
        return filename_payload
    # end try
# end def get_checkstr


def printl(text=""):
    """
    Function for printing text to console and to log file.
    """
    print(text)
    logfile.write(str(text).strip('\r') + '\n')
    logfile.flush()
# end def printl


def get_curr_res_dpath(fq_fa_path, tax_annot_res_dir):
    """
    Function configures and returns the path to result directory for particular FASTA or FASTQ file.
    Result directory is nested in 'tax_annot_res_dir' and is named according to name of FASTA/FASTQ file.
    E.g. if file 'some_reads.fastq' is processing, it's result directory will be named 'some_reads'.

    :param fq_fa_path: path to FASTA/FASTQ file that is procesing;
    :type fq_fa_path: str;
    :param tax_annot_res_dir: path to directory with results of 'prober.py';
    :type tax_annot_res_dir: str;

    Returns path to result directory that was recenly created of 'str' type.
    """

    # dpath means "directory path"
    new_dpath = os.path.join(tax_annot_res_dir, os.path.basename(fq_fa_path)) # get rid of absolute path
    new_dpath = re_search(r"(.*)\.(m)?f(ast)?(a|q)", new_dpath).group(1) # get rid of extention

    return new_dpath
# end def get_curr_res_dir


# There can be some troubles with '.log' extention on Windows, so let's make a .txt file for it:
log_ext = ".log" if not sys.platform.startswith("win") else ".txt"
logfile_path = os.path.join(outdir_path, "fastQA5-sorter_log_{}{}".format(strftime("%Y-%m-%d_%H-%M-%S", localtime(start_time)), log_ext))
logfile = open(logfile_path, 'w')

printl("\n |=== fastQA5-sorter.py (version {}) ===|\n".format(__version__))


# Try to import 'h5py' if at least one FAST5 file is specified to process.
if len(fast5_list) != 0:
    try:
        import h5py
    except ImportError as imperr:
        print(err_fmt("package 'h5py' is not installed"))
        print( "Exact error description given by the interpreter: {}".format(str(imperr)) )
        print("\n  'h5py' package is necessary for FAST5 files sorting.")
        print("  Please, install it (e.g. 'pip3 install h5py').")
        print("  Tip for Linux users: you may need to install 'libhdf5-dev' with your packet manager first and then go to pip.")
        platf_depend_exit(1)
    # end try


    def copy_read_f5_2_f5(from_f5, read_name, to_f5):
        """
        Function copies a read with ID 'read_name'
            from 'from_f5' multiFAST5 file to to_f5 multiFAST5 one.

        :param from_f5: FAST5 file object to copy a read from;
        :type from_f5: h5py.File;
        :param read_name: ID of a read to copy;
        :type read_name: str;
        :param to_f5: destination FAST5 file;
        :type to_f5: h5py.File;
        """
        try:
            # Assign version attribute to '2.0' -- multiFAST5
            if not "file_version" in to_f5.attrs:
                to_f5.attrs["file_version"] = b"2.0"
            # end if
            from_f5.copy(read_name, to_f5)
        except ValueError as verr:
            printl("\n\n ! - Error: {}".format( str(verr) ))
            printl("Reason is probably the following:")
            printl("  read that is copying to the result file is already in it.")
            printl("ID of the read: '{}'".format(read_name))
            printl("File: '{}'".format(to_f5.filename))
            platf_depend_exit(1)
        # end try
    # end def copy_read_f5_2_f5


    def copy_single_f5(from_f5, read_name, to_f5):
        """
        Function copies a read with ID 'read_name'
            from 'from_f5' singleFAST5 file to to_f5 multiFAST5 one.

        :param from_f5: FAST5 file object to copy a read from;
        :type from_f5: h5py.File;
        :param read_name: ID of a read to copy;
        :type read_name: str;
        :param to_f5: destination FAST5 file;
        :type to_f5: h5py.File;
        """
        try:
            # Assign version attribute to '2.0' -- multiFAST5 (output file is always multiFAST5)
            if not "file_version" in to_f5.attrs:
                to_f5.attrs["file_version"] = b"2.0"
            # end if
            read_group = read_name
            to_f5.create_group(read_group)

            for ugk_subgr in from_f5["UniqueGlobalKey"]:
                    from_f5.copy("UniqueGlobalKey/"+ugk_subgr, to_f5[read_group])
            # end for

            read_number_group = "Raw/Reads/"+next(iter(from_f5["Raw"]["Reads"]))
            read_number = re_search(r"(Read_[0-9]+)", read_number_group).group(1)
            from_f5.copy(from_f5[read_number_group], to_f5[read_group])
            to_f5.move("{}/{}".format(read_group, read_number), "{}/Raw".format(read_group))

            for group in from_f5:
                if group != "Raw" and group != "UniqueGlobalKey":
                    from_f5.copy(group, to_f5["/{}".format(read_group)])
                # end if
            # end for
        except ValueError as verr:
            printl("\n\n ! - Error: {}".format( str(verr) ))
            printl("Reason is probably the following:")
            printl("  read that is copying to the result file is already in it.")
            printl("ID of the read: '{}'".format(read_name))
            printl("File: '{}'".format(to_f5.filename))
            platf_depend_exit(1)
        # end try
    # end def copy_single_f5


    def fast5_readids(fast5_file):

        if "Raw" in fast5_file.keys():
            yield "read_" + fmt_read_id(fast5_file.filename)
            return
        else:
            for readid in fast5_file:
                if readid.startswith("read_"):
                    yield readid
                # end if
            # end for
        # end if
        return
    # end def fast5_readids
# end if

if not sys.platform.startswith("win"):
    check_mark = " \u2714"
else:
    check_mark = "OK"
# end if

logfile.write('\n')
printl(getwt() + " ({}) ".format(strftime("%Y-%m-%d %H:%M:%S", localtime(start_time))) + "- Start working\n")


def printn(text):
    """
    Function prints text to the console without adding '\\n' in the end of the line.
    Why not just to use 'print(text, end="")'?
    In order to display informative error message if Python 2.X is launched
        instead if awful error traceback.
    """
    sys.stdout.write(text)
    sys.stdout.flush()
# end def printn


# Make sure that each file meant to be processed has it's directory with TSV result file
#    generated by prober and barapost.
printn("Primary validation...")

for fpath in fast5_list:

    if not untwist_fast5:
        # Get number of directories in 'tax_annot_res_dir' where results of current FAST5
        #    baraposting ar elocated.
        put_fast5_resdirs_num = len( glob("{}{}*{}*".format(tax_annot_res_dir, os.sep, get_checkstr(fpath))) )

        if put_fast5_resdirs_num == 1:
            continue # OK
        elif put_fast5_resdirs_num == 0: # there is no such a directory
            print(err_fmt("""directory that may be considered as valid for sorting of file
  '{}'\n    is not found in the directory '{}'""".format(fpath, tax_annot_res_dir)))
            print("Try running sorter with '-u' ('--untwist-fast5') flag.\n")
            platf_depend_exit(1)
        else: # there are multiple directories where prober-barapost results can be located
            print(err_fmt("multiple result directories match FAST5 file meant to be sorted"))
            print("  Please, contact the developer -- it is his mistake.\n")
            platf_depend_exit(1)
        # end if
    # end if

    try:
        # File existance checking is performed while parsing CL arguments.
        # Therefore, this if-statement will trigger only if f5_path's file is not a valid HDF5 file.
        if not h5py.is_hdf5(fpath):
            raise RuntimeError("file is not of HDF5 (i.e. not FAST5) format")
        # end if
        # Open the file

        f5_file = h5py.File(fpath, 'r')
        # Validation of the file:
        #   RuntimeError will be raised if FAST5 file is broken.
        for _ in f5_file:
            break
        # end for
    except OSError as oserr:
        print(err_fmt("cannot open FAST5 file"))
        printl("Opening file '{}' crashed:".format(os.path.basename(fpath)))
        print("Reason: {}".format( str(oserr) ))
        platf_depend_exit(1)
    except RuntimeError as runterr:
        print(err_fmt("FAST5 file is broken"))
        print("Reading of the file '{}' crashed.".format(os.path.basename(fpath)))
        print("Reason: {}".format( str(runterr) ))
        platf_depend_exit(5)
    finally:
        f5_file.close()
    # end try
# end for

for fpath in fq_fa_list:
    # Validate new_dpath existance for FASTA and FASTQ files:
    if not os.path.isdir( get_curr_res_dpath(fpath, tax_annot_res_dir) ):
        print(err_fmt("prober result directory not found"))
        print("""Directory that should have contained results of taxonomic annotation of the following file:
  '{}' does not exist.""".format(os.path.basename(fpath)))
        print("Please, make sure that this file have been already processed by 'prober.py' and 'barapost.py'.")
        platf_depend_exit(1)
    # end if
# end for

print("\rPrimary validation... {}\n".format(check_mark))


# Check if there are some results in output directory
if len( list( filter(is_fastQA5, os.listdir(outdir_path)) ) ) != 0:
    printl("Attention! Output directory '{}' is not empty!".format(outdir_path))
    printl("List of sequence-containing files in it:")
    for i, file in enumerate(filter(is_fastQA5, os.listdir(outdir_path))):
        printl("  {}. '{}'".format(i+1, file))
    # end for
    print()
    
    invalid_reply = True
    while invalid_reply:
        reply = input("""Press ENTER to ovewrite all old sequence-containing files
    or enter 'r' to rename old directory and to write current results to a new one
    or enter 'a' to append new data to the existing one:>>""")

        if reply == "":
            invalid_reply = False

            for file in filter(is_fastQA5, os.listdir(outdir_path)):
                printl("Removing '{}'".format( os.path.join(outdir_path, file) ))
                os.unlink( os.path.join(outdir_path, file) )
            # end for
            print()
            break
        elif reply == 'r':
            invalid_reply = False

            is_analog = lambda d: os.path.basename(outdir_path) in d
            num_analog_dirs = len( list(filter(is_analog, os.listdir(os.path.dirname(outdir_path)))) )
            
            try:
                printl('\n' + getwt() + " - Renaming old directory:")
                new_name = outdir_path+"_old_"+str(num_analog_dirs)
                printl("  '{}' --> '{}'".format(outdir_path, new_name))
                os.rename(outdir_path, new_name)
            except Exception as err:
                # Anything (and not only strings) can be passed to the function
                printl(err_fmt("directory '{}' cannot be renamed".format( outdir_path )))
                printl(str(err) + '\n')
                platf_depend_exit(1)
            # end try
            print()
        elif reply == 'a':
            invalid_reply = False
        else:
            print("Invalid reply!\n")
        # end if
    # end while
# end if


is_gzipped = lambda f: True if f.endswith(".gz") else False
OPEN_FUNCS = (open, open_as_gzip)

# Data from plain text and gzipped should be parsed in different way,
#   because data from .gz is read as 'bytes', not 'str'.
FORMATTING_FUNCS = (
    lambda line: line,   # format text line
    lambda line: line.decode("utf-8")  # format gzipped line
)


# |===== Create output directory =====|
if not os.path.exists(outdir_path):
    try:
        os.makedirs(outdir_path)
    except Exception as err:
        printl(err_fmt("unable to create output directory!"))
        printl( str(err) )
        platf_depend_exit(1)
    # end try
# end if


# Here we are going to define different functions for different use cases:
#   prallel and single-thread procesing requires different functions that
#   performs writing to and sorting plain (FASTA, FASTQ) files.
# It is better to check number of threads once and define functions that will
#   be as strait-forward as possible rather than check conditions each time in the spaghetti-function.

if n_thr == 1:
    import src.sorter_modules.single_thread as srt_module
else:
    import src.sorter_modules.parallel as srt_module
# end if

srt_module.logfile = logfile
srt_module.tax_annot_res_dir = tax_annot_res_dir
srt_module.sens = sens
srt_module.n_thr = n_thr
srt_module.outdir_path = outdir_path
srt_module.min_ph33_qual = min_ph33_qual
srt_module.min_qlen = min_qlen
minlen_fmt_str = "_len_less_{}".format(min_qlen) if not min_qlen is None else ""
srt_module.minlen_fmt_str = minlen_fmt_str



from threading import Thread, Event

# Value that contains number of processed files:
global inc_val


def status_printer(get_inc_val, stop):
    """
    Function meant to be launched as threading.Thread in order to indicate progress each second.

    :param get_inc_val: function that returns 'inc_val' value -- the number of processed files;
    :param stop: event that will signal printer when to stop;
    :type stop: threading.Event;
    """

    nfiles = len(fq_fa_list) + len(fast5_list)
    printn("{} - 0/{} files processed. Working...".format(getwt(), nfiles))
    saved_val = get_inc_val()
    while stop.is_set():
        loc_inc_val = get_inc_val()
        printn("\r{} - {}/{} files processed. Working...".format(getwt(), loc_inc_val, nfiles))
        if loc_inc_val != saved_val:
            logfile.write("{} - {}/{} files processed.\n".format(getwt(), loc_inc_val, nfiles))
            saved_val = get_inc_val()
        sleep(1)
    # end while
    printn("\r{} - {}/{} files processed.".format(getwt(), get_inc_val(), nfiles) +
        ' '*len(" Working..."))
    logfile.write("{} - {}/{} files processed.\n".format(getwt(), get_inc_val(), nfiles))
# end def status_printer


# If FAST5-untwisting is enabled, we need to import 'shelve' and define two functions.
# And we do not need them otherwise.
if untwist_fast5:

    from shelve import open as open_shelve

    # Names of index files
    index_name = "fast5_to_tsvtaxann_idx"

    # Create index directory
    index_dirpath = os.path.join(tax_annot_res_dir, index_name) # name of directory that will contain indicies
    if not os.path.isdir(index_dirpath):
        try:
            os.makedirs(index_dirpath)
        except OSError as oserr:
            printl(err_fmt("cannot create index directory"))
            printl("Directory that cannot be created: '{}'".format(index_dirpath))
            printl("Reason: '{}'".format( str(oserr) ))
            platf_depend_exit(1)
        # end try
    # end if

    use_old_index = False

    if len(os.listdir(index_dirpath)) != 0:
        printl("Attention! Index file created by '-u' (--untwist_fast5) option exists (left from previous run).")

        error = True

        while error:
            reply = input("""  Press ENTER to make new index file
  or enter 'u' to use old index file:>>""")
            if reply == "":
                error = False
            elif reply == 'u':
                use_old_index = True
                error = False
            else:
                print("Invalid reply!\n")
            # end if
        # end while
        printl("You have chosen to {} index file.\n".format("use old" if use_old_index else "make new"))
    # end if

    # We do not need this function if we do not make new index
    if not use_old_index:
        def map_f5reads_2_taxann(fast5_list):
            """
            Function perform mapping of all reads stored in input FAST5 files
                to existing TSV files containing taxonomic annotation info.

            It creates an index DBM file.

            Generally speaking, reads from one FAST5 are spread between several
            FASTQ (and hence, TSV-taxann) files.
            Structure of our index allows to minimize times needed to read plain
            (i.e. sequential access) TSV files.
            Well, structure of our index is following:

            <DBM file>:
            {
                <path_to_FAST5_1>: {
                                    <path_to_TSV_1.1>: [<read_ID_1.1.1>, <read_ID_1.1.2>, ..., <read_ID_1.1.N>],
                                    <path_to_TSV_1.2>: [<read_ID_1.2.1>, <read_ID_1.2.2>, ..., <read_ID_1.2.N>],
                                    ...
                                    <path_to_TSV_1.M>: [<read_ID_1.M.1>, <read_ID_1.M.2>, ..., <read_ID_1.M.N>]
                                 },
                <path_to_FAST5_2>: {
                                    <path_to_TSV_1.1>: [<read_ID_1.1.1>, <read_ID_1.1.2>, ..., <read_ID_1.1.N>],
                                    <path_to_TSV_1.2>: [<read_ID_1.2.1>, <read_ID_1.2.2>, ..., <read_ID_1.2.N>],
                                    ...
                                    <path_to_TSV_2.M>: [<read_ID_2.M.1>, <read_ID_2.M.2>, ..., <read_ID_2.M.N>]
                                 },
                ...
                <path_to_FAST5_K>: {
                                    <path_to_TSV_K.1>: [<read_ID_K.1.1>, <read_ID_K.1.2>, ..., <read_ID_K.1.N>],
                                    <path_to_TSV_K.2>: [<read_ID_K.2.1>, <read_ID_K.2.2>, ..., <read_ID_K.2.N>],
                                    ...
                                    <path_to_TSV_K.M>: [<read_ID_K.M.1>, <read_ID_K.M.2>, ..., <read_ID_K.M.N>]
                                 },
            }
            """

            # Get all directories nested in 'tax_annot_res_dir'
            taxann_dir_lst = list(filter(lambda f: True if os.path.isdir(f) else False,
                glob( os.path.join(tax_annot_res_dir, "*") )))

            # Exclude "local_database" and "fast5_to_fastq_idx" from this list
            for dir_to_exclude in (index_name, "local_database"):
                ldb_dir_path = os.path.join(tax_annot_res_dir, dir_to_exclude)
                if ldb_dir_path in taxann_dir_lst:
                    taxann_dir_lst.remove(ldb_dir_path)
                # end if
            # end for

            # Get path to TSV files containing taxonomy annotation info
            tsv_taxann_lst = list()
            for taxann_dir in taxann_dir_lst:
                putative_tsvs = glob("{}{}*.tsv".format(taxann_dir, os.sep))
                if len(putative_tsvs) == 1:
                    tsv_taxann_lst.append(putative_tsvs[0])
                elif len(putative_tsvs) == 0:
                    printl("""Warning!  There is no taxonomic annotation info in the following directory:
      '{}'
    Omitting this directory.\n""".format(taxann_dir))
                else:
                    printl("""Error!  Multiple TSV files in the following directory:
      '{}'
    Please, remove extra files and leave only one, which contains actual taxononic annotation info.""".format(taxann_dir))
                    platf_depend_exit(1)
                # end if
            # end for
            del taxann_dir_lst

            printl("{} - Untwisting started.".format(getwt()))

            # Open index files overwriting existing data ('n' parameter)
            index_f5_2_tsv = open_shelve( os.path.join(index_dirpath, index_name), 'n' )

            global inc_val
            inc_val = 0
            get_inc_val = lambda: inc_val # merely return this value (1 thread)

            # Launch printer
            printer = Thread(target=status_printer, args=(get_inc_val, stop)) # create thread
            stop = Event()
            stop.set() # raise the flag
            printer.start() # start waiting

            # Iterate over FAST5 files
            for j, f5_path in enumerate(fast5_list):

                f5_file = h5py.File(f5_path, 'r')# open FAST5 file
                readids_to_seek = list(fast5_readids(f5_file))
                idx_dict = dict() # dictionary for index

                # This saving is needed to compare with 'len(readids_to_seek)'
                #    after all TSV will be looked through in order to
                #    determine if some reads miss taxonomic annotation.
                len_before = len(readids_to_seek)

                # Iterate over TSV-taaxnn file
                for tsv_taxann_fpath in tsv_taxann_lst:

                    with open(tsv_taxann_fpath, 'r') as taxann_file:

                        # Get all read IDs in current TSV
                        readids_in_tsv = list( map(lambda l: l.split('\t')[0], taxann_file.readlines()) )

                        # Iterate over all other reads in current FAST5
                        #    ('reversed' is necessary because we remove items from list in this loop)
                        for readid in reversed(readids_to_seek):
                            if fmt_read_id(readid) in readids_in_tsv:
                                # If not first -- write data to dict (and to index later)
                                try:
                                    idx_dict[tsv_taxann_fpath].append(readid) # append to existing list
                                except KeyError:
                                    idx_dict[tsv_taxann_fpath] = [readid] # create a new list
                                finally:
                                    readids_to_seek.remove(readid)
                                    inc_val += 1
                                # end try
                            # end if
                        # end for
                    # end with
                    if len(readids_to_seek) == 0:
                        break
                    # end if
                # end for

                # If after all TSV is checked but nothing have changed -- we miss taxonomic annotation
                #     for some reads! And we will write their IDs to 'missing_reads_lst.txt' file.
                if len(readids_to_seek) == len_before:
                    printl(err_fmt("reads from FAST5 file not found"))
                    printl("FAST5 file: '{}'".format(f5_path))
                    printl("Some reads reads have not undergone taxonomic annotation.")
                    missing_log = "missing_reads_lst.txt"
                    printl("List of missing reads are in following file:\n  '{}'\n".format(missing_log))
                    with open(missing_log, 'w') as missing_logfile:
                        missing_logfile.write("Missing reads from file '{}':\n\n".format(f5_path))
                        for readid in readids_to_seek:
                            missing_logfile.write(fmt_read_id(readid) + '\n')
                        # end for
                    index_f5_2_tsv.close()
                    try:
                        for path in glob( os.path.join(index_dirpath, '*') ):
                            os.unlink(path)
                        # end for
                        os.rmdir(index_dirpath)
                    except OSError as oserr:
                        printl("error while removing index directory: {}".format(oserr))
                    finally:
                        platf_depend_exit(3)
                    # end try
                # end if

                # Update index
                index_f5_2_tsv[f5_path] = idx_dict
            # end for

            # Stop printer
            stop = True # lower the flag
            printer.join()
            printl()

            index_f5_2_tsv.close()
            printl("{} - Untwisting is completed.".format(getwt()))
            printl('-'*20+'\n')
        # end def map_f5reads_2_taxann
    # end if


    def sort_fast5_file(f5_path):
        """
        Function sorts FAST5 file with untwisting.

        :param f5_path: path to FAST5 file meant to be processed;
        :type f5_path: str;
        """

        seqs_pass = 0
        seqs_fail = 0
        srt_file_dict = dict()

        trash_fpath = os.path.join(outdir_path, "qual_less_Q{}{}.fast5".format(int(min_ph33_qual),
                minlen_fmt_str))

        from_f5 = h5py.File(f5_path, 'r') # open source FAST5
        num_reads = len(from_f5) # get number of reads in it

        # singleFAST5 and multiFAST5 files should be processed in different ways
        # "Raw" group always in singleFAST5 root and never in multiFAST5 root
        if "Raw" in from_f5.keys():
            f5_cpy_func = copy_single_f5
        else:
            f5_cpy_func = copy_read_f5_2_f5
        # end if

        try:
            readids_to_seek = list(from_f5.keys()) # list of not-sorted-yet read IDs
        except Exception as e:
            print(str(e))
            exit(0)
        # end try

        # Fill the list 'readids_to_seek'
        for read_name in fast5_readids(from_f5):
            # Get rid of "read_"
            readids_to_seek.append(sys.intern(read_name))
        # end for

        # Walk through the index
        index_f5_2_tsv = open_shelve( os.path.join(index_dirpath, index_name), 'r' )

        if not f5_path in index_f5_2_tsv.keys():
            printl(err_fmt("Source FAST5 file not found in index"))
            printl("Try to rebuild index")
            platf_depend_exit(1)
        # end if

        for tsv_path in index_f5_2_tsv[f5_path].keys():

            read_names = index_f5_2_tsv[f5_path][tsv_path]
            resfile_lines = configure_resfile_lines(tsv_path)

            for read_name in read_names:
                try:
                    hit_name, ph33_qual, q_len = resfile_lines[sys.intern(fmt_read_id(read_name))]
                except KeyError:
                    printl(err_fmt("missing taxonomic annotation info for read '{}'".format(fmt_read_id(read_name))))
                    printl("It is stored in '{}' FAST5 file".format(f5_path))
                    printl("Try to make new index file (press ENTER on corresponding prompt).")
                    printl("""Or, if does not work for you, make sure that taxonomic annotation info
  for this read is present in one of TSV files generated by 'prober.py' and 'barapost.py'.""")
                    index_f5_2_tsv.close()
                    platf_depend_exit(1)
                else:
                    q_len = SeqLength(q_len)
                    if q_len < min_qlen or (ph33_qual != '-' and ph33_qual < min_ph33_qual):
                        # Get name of result FASTQ file to write this read in
                        if trash_fpath not in srt_file_dict.keys():
                            srt_file_dict = update_file_dict(srt_file_dict, trash_fpath)
                        # end if
                        f5_cpy_func(from_f5, read_name, srt_file_dict[trash_fpath])
                        seqs_fail += 1
                    else:
                        # Get name of result FASTQ file to write this read in
                        sorted_file_path = os.path.join(outdir_path, "{}.fast5".format(hit_name))
                        if sorted_file_path not in srt_file_dict.keys():
                            srt_file_dict = update_file_dict(srt_file_dict, sorted_file_path)
                        # end if
                        f5_cpy_func(from_f5, read_name, srt_file_dict[sorted_file_path])
                        seqs_pass += 1
                    # end if
                # end try
            # end for

        index_f5_2_tsv.close()
        # Close all sorted files
        for file_obj in srt_file_dict.values():
            file_obj.close()
        # end for
        return (seqs_pass, seqs_fail)
    # end def sort_fast5_file

else: # if untwisting is not enabled, this function will be different

    def sort_fast5_file(f5_path):
        """
        Function sorts FAST5 file without untwisting.

        :param f5_path: path to FAST5 file meant to be processed;
        :type f5_path: str;
        """

        seqs_pass = 0
        seqs_fail = 0
        srt_file_dict = dict()

        trash_fpath = os.path.join(outdir_path, "qual_less_Q{}{}.fast5".format(int(min_ph33_qual),
                minlen_fmt_str))

        new_dpath = glob("{}{}*{}*".format(tax_annot_res_dir, os.sep, get_checkstr(f5_path)))[0]
        tsv_res_fpath = get_res_tsv_fpath(new_dpath)
        resfile_lines = configure_resfile_lines(tsv_res_fpath)

        from_f5 = h5py.File(f5_path, 'r')
        num_reads = len(from_f5)

        # singleFAST5 and multiFAST5 files should be processed in different ways
        # "Raw" group always in singleFAST5 root and never in multiFAST5 root
        if "Raw" in from_f5.keys():
            f5_cpy_func = copy_single_f5
        else:
            f5_cpy_func = copy_read_f5_2_f5
        # end if

        for i, read_name in enumerate(fast5_readids(from_f5)):

            try:
                hit_name, ph33_qual, q_len = resfile_lines[sys.intern(fmt_read_id(read_name))] # omit 'read_' in the beginning of FAST5 group's name
            except KeyError:
                printl(err_fmt("""read '{}' not found in TSV file containing taxonomic annotation.
      This TSV file: '{}'""".format(fmt_read_id(read_name), tsv_res_fpath)))
                printl("Try running sorter with '-u' (--untwist-fast5') flag.\n")
                platf_depend_exit(1)
            # If read is found in TSV file:
            else:
                q_len = SeqLength(q_len)
                if ph33_qual != '-' and ph33_qual < min_ph33_qual:
                    # Get name of result FASTQ file to write this read in
                    if trash_fpath not in srt_file_dict.keys():
                        srt_file_dict = update_file_dict(srt_file_dict, trash_fpath)
                    # end if
                    f5_cpy_func(from_f5, read_name, srt_file_dict[trash_fpath])
                    seqs_fail += 1
                else:
                    # Get name of result FASTQ file to write this read in
                    sorted_file_path = os.path.join(outdir_path, "{}.fast5".format(hit_name))
                    if sorted_file_path not in srt_file_dict.keys():
                        srt_file_dict = update_file_dict(srt_file_dict, sorted_file_path)
                    # end if
                    f5_cpy_func(from_f5, read_name, srt_file_dict[sorted_file_path])
                    seqs_pass += 1
                # end if
            # end try
        # end for
        # Close all sorted files
        for file_obj in srt_file_dict.values():
            file_obj.close()
        # end for
        return (seqs_pass, seqs_fail)
    # end def sort_fast5_file
# end if


# |===== Proceed =====|

printl(" - Output directory: '{}';".format(outdir_path))
printl(" - Sorting sensitivity: '{}';".format(sens))
printl(" - Minimum mean Phred33 quality of a read to keep: {};".format(min_ph33_qual))
printl(" - Minimum length of a read to keep: {};".format(min_qlen if not min_qlen is None else "unlimited"))
printl(" - Threads: {}".format(n_thr))
if untwist_fast5:
    printl(" - \"FAST5 untwisting\" is enabled.")
# end if

num_files = len(fq_fa_list) + len(fast5_list)

s_letter = '' if num_files == 1 else 's'
printl("\n {} file{} will be processed.".format( num_files, s_letter))
logfile.write("Here they are:\n")
i = 1
for path in fq_fa_list:
    logfile.write("    {}. '{}'\n".format(i, path))
    i += 1
# end for
for path in fast5_list:
    logfile.write("    {}. '{}'\n".format(i, path))
    i += 1
# end for

printl('-' * 30 + '\n')

seqs_pass, seqs_fail = 0, 0

if untwist_fast5 and not use_old_index:
    map_f5reads_2_taxann(fast5_list)
# end if


def kernel(fpath):

    seqs_pass, seqs_fail = 0, 0
    parallel = n_thr != 1

    if not parallel:
        global inc_val
    # end if

    # Interface of interaction with HDF5 files are quite different from plain text ones.
    # So it is beter to write a separate function for them.
    srt_func = srt_module.sort_fastqa_file if not fpath.endswith(".fast5") else srt_module.sort_fast5_file
    buff_res = srt_func(fpath)
    seqs_pass += buff_res[0]
    seqs_fail += buff_res[1]

    if parallel:
        with inc_val_lock:
            inc_val.value += 1
        # end if
    else:
        inc_val += 1
    # end if

    return (seqs_pass, seqs_fail)
# end if


printl("{} - Sorting started.".format(getwt()))

stop = Event()
stop.set() # raise the flag
res_stats = list()

if n_thr == 1:

    inc_val = 0
    get_inc_val = lambda: inc_val # merely get this value (1 thread)

    # Launch printer
    printer = Thread(target=status_printer, args=(get_inc_val, stop), daemon=True) # create thread
    printer.start() # start waiting

    # Sort FAST5 files:
    res_stats.extend( list(map(kernel, fast5_list)) )

    # Sort FASTA and FASTQ files:
    res_stats.extend( list(map(kernel, fq_fa_list)) )

    # Summarize statistics
    seqs_pass = sum(map(lambda x: x[0], buff_res))
    seqs_fail = sum(map(lambda x: x[1], buff_res))

else:
    inc_val = mp.Value('i', 0)
    get_inc_val = lambda: inc_val.value # get shared value (multiple threads)

    write_lock = mp.Lock()
    inc_val_lock = mp.Lock()

    # Launch printer
    printer = Thread(target=status_printer, args=(get_inc_val, stop), daemon=True) # create thread
    printer.start() # start waiting

    # Sort FAST5 files:
    pool = mp.Pool(n_thr, initializer=srt_module.init_paral_sorting, initargs=(write_lock, inc_val, inc_val_lock))
    res_stats.extend(pool.starmap(kernel, [(sublist,) for sublist in fast5_list]))
    pool.close()
    pool.join()

    # Sort FASTA and FASTQ files:
    pool = mp.Pool(n_thr, initializer=srt_module.init_paral_sorting, initargs=(write_lock, inc_val, inc_val_lock))
    res_stats.extend(pool.starmap(kernel, [(sublist,) for sublist in fq_fa_list]))
    pool.close()
    pool.join()

    # Summarize statistics
    seqs_pass = sum(map(lambda t: t[0], res_stats))
    seqs_fail = sum(map(lambda t: t[1], res_stats))
# end if

# Stop printer
stop.clear() # lower the flag
printer.join()
printl()


def get_undr_sep_number(number):
    undr_sep_num = str(number)
    for i in range(len(undr_sep_num)-4, -1, -4):
        undr_sep_num = undr_sep_num[: i+1] + '_' + undr_sep_num[i+1: ]
    # end for
    return undr_sep_num
# end def get_undr_sep_number


printl("\n{} sequences have been processed.".format(get_undr_sep_number(seqs_pass + seqs_fail)))
if seqs_fail > 0:
    len_fmt_str = " and length ({} bp)".format(min_qlen) if not min_qlen is None else ""
    printl("{} of them have passed quality (Q{}){} controle.".format(get_undr_sep_number(seqs_pass),
        int(min_ph33_qual), len_fmt_str))
# end if
printl()

fastqa_res_files = list(filter(is_fastqa, glob(os.path.join(outdir_path, '*'))))

# Exit now if there is nothing to compress

if len(fastqa_res_files) == 0 and not compress:
    end_time = time()
    printl('\n'+getwt() + " ({}) ".format(strftime("%Y-%m-%d %H:%M:%S", localtime(end_time))) + "- Sorting is completed!\n")
    platf_depend_exit(0)
# end if

# Otherwise -- proceed gzipping

printl("{} - Gzipping output files started".format(getwt()))

# GNU gzip utility is faster, but there can be presence of absence of it :)
gzip_util = "gzip"
util_found = False
for directory in os.environ["PATH"].split(os.pathsep):
    if os.path.isdir(directory) and gzip_util in os.listdir(directory):
        util_found = True
        break
    # end if
# end for

# Define function that will gzip files

if util_found:

    def gzip_func(fpath):
        """Function that compresses output FASTA and FASTQ files with gzip utility.
        
        :param fpath: path to file to compress;
        :type fpath: str;
        """
        try:
            os.system("{} {}".format(gzip_util, fpath))
        except OSError as oserr:
            printl(err_fmt("cannot gzip file '{}'".format(os.path.basename(fpath))))
            printl("Reason: {}".format( str(oserr) ))
            # Try to gzip others -- continue loop
        else:
            printl("{} - Gzipping '{}' completed".format(getwt(), os.path.basename(fpath)))
        # end try
    # end def gzip_func
else:

    from shutil import copyfileobj as shutil_copyfileobj

    def gzip_func(fpath):
        """Function that compresses output FASTA and FASTQ files with Python gzip and shutil modules.
        
        :param fpath: path to file to compress;
        :type fpath: str;
        """
        try:
            # form .fasta.gz file 'by hand'
            with open(fpath, 'rb') as fastqa_file, open_as_gzip(fpath+".gz", "wb") as faqgz_file:
                shutil_copyfileobj(fastqa_file, faqgz_file)
            # end with
            os.unlink(fpath) # remove plain FASTA file
        except OSError as oserr:
            printl(err_fmt("cannot gzip file '{}'".format(os.path.basename(fpath))))
            printl("Reason: {}".format( str(oserr) ))
            # Try to gzip others -- continue loop
        else:
            printl("{} - Gzipping '{}' completed".format(getwt(), os.path.basename(fpath)))
        # end try
    # end def gzip_func
# end if

if n_thr == 1: # single-thread compressing

    gzip_func(fastqa_res_files)

else: # compress in parallel
    pool = mp.Pool(n_thr)
    pool.starmap(gzip_func, [(fastqa_sublist,) for fastqa_sublist in fastqa_res_files])
    pool.close()
    pool.join()
# end if
printl("{} - Gzipping output files completed".format(getwt()))

end_time = time()
printl('\n'+getwt() + " ({}) ".format(strftime("%Y-%m-%d %H:%M:%S", localtime(end_time))) + "- Sorting is completed!\n")
logfile.close()
platf_depend_exit(0)