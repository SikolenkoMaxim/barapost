#!/usr/bin/env python3
# -*- coding: utf-8 -*-

__version__ = "3.3.d"
# Year, month, day
__last_update_date__ = "2019.11.11"

# |===== Check python interpreter version =====|

from sys import version_info as verinf

if verinf.major < 3:
    print( "\nYour python interpreter version is " + "%d.%d" % (verinf.major, verinf.minor) )
    print("   Please, use Python 3!\a")
    # In python 2 'raw_input' does the same thing as 'input' in python 3.
    # Neither does 'input' in python2.
    raw_input("Press ENTER to exit:")
    exit(1)
# end if

from sys import platform

def platf_depend_exit(exit_code):
    """
    A function that asks to press ENTER on Windows
        and exits.

    :type exit_code: int;
    """
    if platform.startswith("win"):
        input("Press ENTER to exit:")
    # end if
    exit(exit_code)
# end def platf_depend_exit


help_msg = """
  fastQA5-sorter.py
  Version {}; {} edition;\n
DESCRIPTION:\n
fastQA5-sorter.py -- this script is designed for sorting (dividing into separate files)
    FASTQ and FASTA files processed by "barapost.py".\n
Moreover, it can sort FAST5 files according to taxonomical annotation of FASTQ files,
    that are result of basecalling these FAST5 files. For details, see README.md
    on github page ('FAST5 sorting' section): https://github.com/masikol/barapost\n
"fastQA5-sorter.py" is meant to be used just after "barapost.py".
----------------------------------------------------------\n
Default parameters:\n
- all FASTQ, FASTA and FAST5 files in current directory will be processed;
- sorting sensitivity (see '-s' option): 'genus';
- output directory ('-o' option): directory named '"fastQA5_sorter_result_<date_and_time_of_run>"''
  nested in current directory;
- minimum mean quality of a read to keep ('-q' option): 20 (Phred33);
- length filtering ('-m' option) is disabled;
- "FAST5 untwisting" is disaled by default;
----------------------------------------------------------\n
Files that you want 'fastQA5-sorter.py' to process should be
    specified as positional arguments (see EXAMPLE #2 below).
Wildcards do work: './fastQA5-sorter.py my_directory/*'' will process all files in 'my_directory'.
----------------------------------------------------------\n
OPTIONS:\n
    -h (--help) --- show help message;\n
    -v (--version) --- show version;\n
    -r (--taxannot-resdir) --- result directory genearted by script 'prober.py'
        This is directory specified to 'prober.py' by '-o' option.
        Default value is "barapost_result", since it is the default name of
        output directory generated by "prober.py".
    -d (--indir) --- directory which contains FAST(Q/A/5) files
        (FASTQ and FASTA files can be gzipped) meant to be sorted;\n
    -o (--outdir) --- output directory;\n
    -s (--sorting-sensitivity) --- sorting sensitivity,
        i.e. the lowest taxonomy rank that will be used in names of resut files;
        Available values: 'genus', 'species', 'strain'; Default is 'genus'.\n
    -q (--min-ph33-qual) --- minimum mean Phred33 quality of a read to keep;
        Reads of lower quality will be written to separate "trash" file;
        Default value: 20;\n
    -m (--min_seq_len) --- minimum length of a sequence to keep.
        Shorter sequences will be written to separate "trash" file.
        Length filtering is disabled by default;
    -u (--untwist-fast5) --- flag option. If specified, FAST5 files will be
        sorted considering that they and "corresponding" FASTQ files contain
        different reads (like after basecalling performed by Guppy).
        Disabled by default;
----------------------------------------------------------\n
EXAMPLES:\n
  1. Process all FASTA and FASTQ files in working directory with default settings:\n
    ./fastQA5-sorter.py\n
  2. Process all files in the working directory that start with "some_my_fastq".
     Ignore reads with mean Phred33 quality < 15. The rest of settings are default:\n
     ./fastQA5-sorter.py some_my_fastq* -q 15\n
  2. Process one FASTQ file with default settings.
     File 'reads.fastq' has been already processed by "barapost.py".
     Results of "barapost.py" work are in directory 'prober_outdir':\n
     ./fastQA5-sorter.py reads.fastq.gz -r prober_outdir/\n
  3. Process a FASTQ file and a FASTA file, place results in 'outdir' directory.
     Files 'reads.fastq.gz' and 'another_sequences.fasta' have been already processed by "barapost.py".
     Results of "barapost.py" work are in directory 'prober_outdir':\n
     ./fastQA5-sorter.py reads_1.fastq.gz some_sequences_2.fasta -o outdir -r prober_outdir/\n
  4. Process all FASTQ and FASTA files in directory named 'dir_with_seqs'. Sort by species.
     All these files have been already processed by "barapost.py". Perform "FAST5 untwisting".
     Results of "barapost.py" work are in directory 'prober_outdir':\n
     ./fastQA5-sorter.py -d dir_with_seqs -o outdir -r prober_outdir/ -s species -u
""".format(__version__, __last_update_date__)

from sys import argv

# First search for information-providing options:

if "-h" in argv[1:] or "--help" in argv[1:]:
    print(help_msg)
    platf_depend_exit(0)
# end if

if "-v" in argv[1:] or "--version" in argv[1:]:
    print(__version__)
    platf_depend_exit(0)
# end if

def err_fmt(text):
    """Function for configuring error messages"""
    return "\n   \a!! - ERROR: " + text + '\n'
# end def print_error


from sys import stdout as sys_stdout
def printn(text):
    """
    Function prints text to the console without adding '\\n' in the end of the line.
    Why not just to use 'print(text, end="")'?
    In order to display informative error message if Python 2.X is launched
        instead if awful error traceback.
    """
    sys_stdout.write(text)
    sys_stdout.flush()
# end def printn

# |===== Stuff for dealing with time =====|

from time import time, strftime, localtime, sleep, gmtime
start_time = time()


def get_work_time():
    return strftime("%H:%M:%S", gmtime( time() - start_time ))
# end def get_work_time


# Get start time
from datetime import datetime
now = datetime.now().strftime("%Y-%m-%d %H.%M.%S")
# -------------------

from gzip import open as open_as_gzip
from re import search as re_search
from glob import glob
import os
from sys import intern
import getopt


try:
    opts, args = getopt.gnu_getopt(argv[1:], "hvr:d:o:s:q:m:u", ["help", "version", "taxannot-resdir=", "indir=", "outdir=",
        "sorting-sensitivity=", "min-ph33-qual=", "min-seq-len=", "untwist-fast5"])
except getopt.GetoptError as gerr:
    print( str(gerr) )
    platf_depend_exit(2)
# end try

is_fastQA5 = lambda f: True if not re_search(r".*\.(m)?f(ast)?(a|q|5)(\.gz)?$", f) is None else False
QA5_list = list() # input FASTQ files paths
tax_annot_res_dir = "barapost_result" # path to result TSV file generated by barapost.py
indir_path = None # path to input directory
outdir_path = "fastQA5_sorter_result_{}".format(now.replace(' ', '_')) # defalut value
sens = "genus" # default value
min_ph33_qual = 20 # minimum mean read quality to keep
min_qlen = None # minimum seqeunce length to keep (unlimited by delault)
untwist_fast5 = False

# This varible will be True if at least one FAST5 file is meant to be processed.
# It is necessary in order not to import 'h5py' module if it is not needed.
fast5_in_inp_files = False

# Add positional arguments to QA5_list
for arg in args:
    if not os.path.exists(arg):
        print(err_fmt("file does not exist:\n '{}'".format(os.path.abspath(arg))))
        platf_depend_exit(1)
    # end if
    if not is_fastQA5(arg):
        print(err_fmt("invalid positional argument: '{}'".format(arg)))
        print("Only FAST(A/Q/5) files can be specified without a key in command line.")
        platf_depend_exit(1)
    # end if
    QA5_list.append( os.path.abspath(arg) )
# end for

for opt, arg in opts:

    if opt in ("-d", "--indir"):
        if not os.path.exists(arg):
            print(err_fmt("directory '{}' does not exist!".format(arg)))
            platf_depend_exit(1)
        # end if
        
        if not os.path.isdir(arg):
            print(err_fmt("'{}' is not a directory!".format(arg)))
            platf_depend_exit(1)
        # end if
        indir_path = os.path.abspath(arg)

        QA5_list.extend(list( filter(is_fastQA5, glob("{}{}*".format(indir_path, os.sep))) ))
    # end if

    if opt in ("-o", "--outdir"):
        outdir_path = os.path.abspath(arg)
    # end if

    if opt in ("-r", "--taxannot-resdir"):
        if not os.path.exists(arg):
            print(err_fmt("directory '{}' does not exist!".format(arg)))
            platf_depend_exit(1)
        # end if
        if not os.path.isdir(arg):
            print(err_fmt("'{}' is not a directory!".format(arg)))
            platf_depend_exit(1)
        # end if
        tax_annot_res_dir = arg
    # end if

    if opt in ("-s", "--sorting-sensitivity"):
        if arg not in ("genus", "species", "strain"):
            print(err_fmt("invalid value specified by '-s' option!\n"))
            print("Available values: 'genus', 'species', 'strain'")
            print("\nType for help:\n    ./fastQA5-sorter.py -h")
            platf_depend_exit(1)
        # end if
        sens = arg
    # end if

    if opt in ("-q", "--min-ph33-qual"):
        try:
            min_ph33_qual = float(arg)
            if min_ph33_qual < 0:
                raise ValueError
            # end if
        except ValueError:
            print(err_fmt("min Phred33 quality must be positive number!"))
            print("You've specified '{}'".format(arg))
            platf_depend_exit(1)
        # end try
    # end if

    if opt in ("-m", "--min_seq_len"):
        try:
            min_qlen = int(arg)
            if min_qlen < 0:
                raise ValueError
            # end if
        except ValueError:
            print(err_fmt("minimum length of the sequence must be positive integer number!"))
            print("You've specified '{}'".format(arg))
            platf_depend_exit(1)
        # end try
    # end if

    if opt in ("-u", "--untwist-fast5"):
        untwist_fast5 = True
    # end if
# end for

# Check if "prober result" directory is specified
if not os.path.exists(tax_annot_res_dir):
    print(err_fmt("file '{}' does not exist!".format(tax_annot_res_dir)))
    if tax_annot_res_dir == "barapost_result":
        print("""Maybe, output directory generated by 'prober.py' hasn't been named 'barapost_result'
    and you have forgotten to specify '-r' option.""")
    platf_depend_exit(1)
    # end if
# end if

# If no FAST(A/Q/5) file have been found
if len(QA5_list) == 0:
    # If input directory was specified -- exit
    if not indir_path is None:
        print(err_fmt("no input FAST(Q/A/5) files specified OR there is no FAST(Q/A/5) files in the input directory.\n"))
        platf_depend_exit(1)
    # If input directory was not specified -- look for FASTQ and FASTA files in current directory
    else:
        QA5_list.extend(list(filter( is_fastQA5, glob("{}{}*".format(os.getcwd(), os.sep)) )))
    # end if
# end if

for fpath in QA5_list:
    if fpath.endswith(".fast5"):
        fast5_in_inp_files = True
        break
    # end if
# end for

if not fast5_in_inp_files and untwist_fast5:
    print("\nWarning! No FAST5 file has been given to sorter's input.")
    print("Therefore, '-u' (--untwist-fast5) flag does not make any sense.")
    print("Ignoring it.")
    untwist_fast5 = False
# end if

QA5_list.sort() # sort list of input files in order to process them in alphabetical order

# Create output directory
if not os.path.isdir(outdir_path):
    try:
        os.makedirs(outdir_path)
    except OSError as oserr:
        print(err_fmt("unable to create result directory"))
        print("fastQA5-sorter just tried to create directory '{}' and crushed.".format(outdir_path))
        print("Reason: {}".format( str(oserr) ))
        platf_depend_exit(1)
    # end try
# end if


def get_checkstr(fast5_fpath):
    """
    Function returns string that will help fasQA5-sorter to find
        TSV file generated by prober and barapost while provessing FASTQ file
        that in turn is basecalled 'fast5_fpath'-file.
    
    Function first searches for ID given to file by programs like of MinKNOW.
    That is:
        1) sequence of 40 (I've seen 40, maybe there can be other number)
        latin letters in lower case interlaced with numbers;
        2) underscore;
        3) number of file within sequenator run;
    For example: file named "FAK94973_e6f2851ddd414655574208c18f2f51e590bf4b27_0.fast5"
        has checkstring "e6f2851ddd414655574208c18f2f51e590bf4b27_0".
    "FAK94973" is not regarding because it can be pruned by basecaller. For example, Guppy acts in this way.

    If no such distinctive string is found in FAST5 file name
        (file can be renamed by the user after sequensing)
        whole file name (except of the '.fast5' extention) is returned as checksting.

    :param fast5_fpath: path to FAST5 file meant to be processed;
    :type fast5_fpath: str;

    Returns checkstring described above.
    """

    try:
        # I'll lower the 40-character barrier down to 30 just in case.
        filename_payload = re_search(r"([a-zA-Z0-9]{30,}_[0-9]+)", fast5_fpath).group(1)
    except AttributeError:
        return os.path.basename(fast5_fpath).replace(".fast5", "")
    else:
        return filename_payload
    # end try
# end def get_checkstr


def get_curr_res_dir(fq_fa_path, tax_annot_res_dir):
    """
    Function returns path to current result directory. This current result directory corresponds to
        the file that is sorted now.

    :param fq_fa_path: path to FASTA or FASTQ file that is sorted now;
    :type fq_fa_path: str;
    :param tax_annot_res_dir: path to "prober result" directory.
        Current result directory is it's subdirectory;
    :type tax_annot_res_dir: str;
    """

    # dpath means "directory path"
    new_dpath = os.path.join(tax_annot_res_dir, os.path.basename(fq_fa_path)) # get rid of absolute path
    new_dpath = re_search(r"(.*)\.(m)?f(ast)?(a|q)", new_dpath).group(1) # get rid of extention

    return new_dpath
# end def get_curr_res_dir

del help_msg # we do not need this large string object any more

def printl(text=""):
    """
    Function for printing text to console and to log file.
    """
    print(text)
    logfile.write(str(text).strip('\r') + '\n')
    logfile.flush()
# end def printl

# There some troubles with file extention on Windows, so let's make a .txt file for it:
log_ext = ".log" if not platform.startswith("win") else ".txt"
logfile_path = os.path.join(outdir_path, "fastQA5-sorter_log_{}{}".format(strftime("%Y-%m-%d_%H-%M-%S", localtime(start_time)), log_ext))
logfile = open(logfile_path, 'w')

printl(("\n |=== fastQA5-sorter.py (version {}) ===|\n".format(__version__)))


# Try to import 'h5py' if at least FAST5 file is meant to be specified.
if fast5_in_inp_files:
    try:
        import h5py
    except ImportError as imperr:
        print(err_fmt("package 'h5py' is not installed"))
        print( "Exact error description given by the interpreter: {}".format(str(imperr)) )
        print("\n  'h5py' package is necessary for FAST5 files sorting.")
        print("  Please, install it (e.g. 'pip3 install h5py').")
        print("  Tip for Linux users: you may need to install 'libhdf5-dev' with your packet manager first and then go to pip.")
        platf_depend_exit(1)
    # end try


    def copy_read_f5_2_f5(from_f5, read_name, to_fpath):
        """
        Function copies a read with ID 'read_name'
            from 'from_f5' FAST5 file to to_fpath one.

        :param from_f5: FAST5 file object to copy a read from;
        :type from_f5: h5py.File;
        :param read_name: ID of a read to copy;
        :type read_name: str;
        :param to_fpath: path to destination FAST5 file;
        :type to_fpath: str;
        """
        try:
            to_f5 = h5py.File(to_fpath, 'a')
            from_f5.copy(read_name, to_f5)
        except OSError as oserr:
            printl(err_fmt("cannot open FAST5 file"))
            printl("Sorter crushed while opening file '{}'".format(os.path.basename(to_f5)))
            printl( "Reason: {}".format( str(oserr) ) )
            platf_depend_exit(1)
        except ValueError as verr:
            printl("\n\n ! - Warning: {}".format( str(verr) ))
            printl("Reason is probably the following:")
            printl("  read that is copying to the result file is already in it.")
            printl("ID of the read: '{}'".format(read_name))
            printl("File: '{}'".format(to_fpath))
            printl("Omitting this read...\n")
        # end try
    # end def copy_read_f5_2_f5
# end if

if not platform.startswith("win"):
    check_mark = " \u2714"
else:
    check_mark = "OK"
# end if


# Make sure that each file meant to be processed has it's directory with TSV result file
#    generated by prober and barapost.
printn("Primary validation...")
for fpath in QA5_list:

    if fpath.endswith("fast5"):

        if not untwist_fast5:
            # Get number of directories in 'tax_annot_res_dir' where results of current FAST5
            #    baraposting ar elocated.
            put_fast5_resdirs_num = len( glob("{}{}*{}*".format(tax_annot_res_dir, os.sep, get_checkstr(fpath))) )

            if put_fast5_resdirs_num == 1:
                continue # OK
            elif put_fast5_resdirs_num == 0: # there is no such a directory
                print(err_fmt("""directory that may be considered as valid for sorting of file
      '{}'\n    is not found in the directory '{}'""".format(fpath, tax_annot_res_dir)))
                print("Try running sorter with '-u' ('--untwist-fast5') flag.\n")
                platf_depend_exit(1)
            else: # there are multiple directories where prober-barapost results can be located
                print(err_fmt("multiple result directories match FAST5 file meant to be sorted"))
                print("  Please, contact the developer -- it is his mistake.\n")
                platf_depend_exit(1)
            # end if
        # end if

        try:
            # File existance checking is performed while parsing CL arguments.
            # Therefore, this if-statement will trigger only if f5_path's file is not a valid HDF5 file.
            if not h5py.is_hdf5(fpath):
                raise RuntimeError("file is not of HDF5 (i.e. not FAST5) format")
            # end if
            # Open the file

            f5_file = h5py.File(fpath, 'r')
            # Validation of the file:
            #   RuntimeError will be raised if FAST5 file is broken.
            for _ in f5_file:
                break
            # end for
        except OSError as oserr:
            print(err_fmt("cannot open FAST5 file"))
            printl("Opening file '{}' crashed:".format(os.path.basename(fpath)))
            print("Reason: {}".format( str(oserr) ))
            platf_depend_exit(1)
        except RuntimeError as runterr:
            print(err_fmt("FAST5 file is broken"))
            print("Reading of the file '{}' crashed.".format(os.path.basename(fpath)))
            print("Reason: {}".format( str(runterr) ))
            platf_depend_exit(5)
        finally:
            f5_file.close()
        # end try
    else:
        # Validate new_dpath existance for FASTA and FASTQ files:
        if not os.path.isdir( get_curr_res_dir(fpath, tax_annot_res_dir) ):
            print(err_fmt("prober result directory not found"))
            print("""Directory that should have contained results of taxonomic annotation of the following file:
    '{}' does not exist.""".format(os.path.basename(fpath)))
            print("Please, make sure that this file have been already processed by 'prober.py' and 'barapost.py'.")
            platf_depend_exit(1)
    # end if
# end for
print("\rPrimary validation... {}\n".format(check_mark))


# Check if there are some results in output directory
if len( list( filter(is_fastQA5, os.listdir(outdir_path)) ) ) != 0:
    printl("Attention! Output directory '{}' is not empty!".format(outdir_path))
    printl("List of sequence-containing files in it:")
    for i, file in enumerate(filter(is_fastQA5, os.listdir(outdir_path))):
        printl("  {}. '{}'".format(i+1, file))
    # end for
    print()
    
    invalid_reply = True
    while invalid_reply:
        reply = input("""Press ENTER to ovewrite all old sequence-containing files
    or enter 'r' to rename old directory and to write current results to a new one
    or enter 'a' to append new data to the existing one:>>""")

        if reply == "":
            invalid_reply = False

            for file in filter(is_fastQA5, os.listdir(outdir_path)):
                printl("Removing '{}'".format( os.path.join(outdir_path, file) ))
                os.unlink( os.path.join(outdir_path, file) )
            # end for
            print()
            break
        elif reply == 'r':
            invalid_reply = False

            is_analog = lambda d: os.path.basename(outdir_path) in d
            num_analog_dirs = len( list(filter(is_analog, os.listdir(os.path.dirname(outdir_path)))) )
            
            try:
                printl('\n' + get_work_time() + " - Renaming old directory:")
                new_name = outdir_path+"_old_"+str(num_analog_dirs)
                printl("  '{}' --> '{}'".format(outdir_path, new_name))
                os.rename(outdir_path, new_name)
            except Exception as err:
                # Anything (and not only strings) can be passed to the function
                printl(err_fmt("directory '{}' cannot be renamed".format( outdir_path )))
                printl( str(err) + '\n')
                platf_depend_exit(1)
            # end try
            print()
        elif reply == 'a':
            invalid_reply = False
        else:
            print("Invalid reply!\n")
        # end if
    # end while
# end if

#                                      Genus    species                   strain name and anything after it
hit_name_patt = r"(PREDICTED)?(:)?(_)?[A-Z][\.a-z]+_[a-z]*(sp\.)?(phage)?_(strain_)?.+$"
# There is an accession number in the beginning of local FASTA file
local_name_hit_patt = r"OWN_SEQ_[0-9]+_"
# Pattern that will match ID of seqeunce in FASTA file generated by SPAdes
spades_patt = r"(NODE)_([0-9]+)"
# Pattern that will match ID of seqeunce in FASTA file generated by a5
a5_patt = r"(scaffold)_([0-9]+)"
# Pattern that will match file path in sequence ID
path_patt = r"\(_(.+)_\)"


def format_taxonomy_name(hit_name, sens):
    """
    Function formats taxonomy name according to chosen sensibiliry of sorting.
    :param hit_name: full_fit_name_of_the_subject_sequence;
    :type hit_name: str;
    :param sens: sensibility returned by 'get_classif_sensibility()' function.
        It's value can be one of the following strings: "genus", "sprcies", "strain";
    :type sens: str;
    Returns formatted hit name of 'str' type;
    """

    # This string can be edited in this funtion, original hei name will be kept intact
    modif_hit_name = hit_name.strip()

    # If there is no hit -- we are sure what to do!
    if modif_hit_name == "No significant similarity found":
        return "unknown"
    # end if

    # Check if hit is a sequence from SPAdes or a5 assembly:
    spades_match_obj = re_search(spades_patt, modif_hit_name)
    a5_match_obj = re_search(a5_patt, modif_hit_name)

    for match_obj in (spades_match_obj, a5_match_obj):

        # If hit is a sequence from SPAdes or a5 assembly
        if not match_obj is None:

            # Find path to file with assembly:
            assm_path = re_search(path_patt, modif_hit_name).group(1)

            node_or_scaff = match_obj.group(1) # get word "NODE" or "scaffold"
            node_scaff_num = match_obj.group(2) # get it's number

            # SPAdes generate "NODEs"
            if node_or_scaff == "NODE":
                assmblr_name = "SPAdes"
            # a5 generates "scaffolds"
            elif node_or_scaff == "scaffold":
                assmblr_name = "a5"
            # There cannot be enything else
            else:
                print(err_fmt("signature of seq id from assembly not recognized: '{}'".format(hit_name)))
                platf_depend_exit(1)
            # end if

            # Include file path to sorted file name
            # Replace path separetor with underscore in order not to held a bacchanalia in file system.
            if assm_path is not None:
                if sens == "genus":
                    # Return only path and "NODE" in case of SPAdes and "scaffold" in case of a5
                    return '_'.join( (assmblr_name, "assembly", assm_path.replace(os.sep, '_'), node_or_scaff) )
                else:
                    # Return path and "NODE_<N>" in case of SPAdes and "scaffold_<N>" in case of a5
                    return '_'.join( (assmblr_name, "assembly", assm_path.replace(os.sep, '_'), node_or_scaff,
                        node_scaff_num) )
                # end if
            else:
                if sens == "genus":
                    # Return only "NODE" in case of SPAdes and "scaffold" in case of a5
                    return assmblr_name + "_assembly_" + node_or_scaff
                else:
                    # Return "NODE_<N>" in case of SPAdes and "scaffold_<N>" in case of a5
                    return '_'.join( (assmblr_name + "assembly", node_or_scaff, node_scaff_num ))
                # end if
            # end if
        # end if
    # end for

    # If structure of hit name is strange
    if re_search(hit_name_patt, modif_hit_name) is None:
        return modif_hit_name.strip().replace(' ', '_')   # return full name
    # end if

    taxa_name = modif_hit_name.partition(',')[0]
    taxa_splitnames = taxa_name.strip().split('_')

    # Sometimes query sequence hits records lke this:
    # XM_009008688, 'PREDICTED: Callithrix jacchus cyclin dependent kinase inhibitor 1C (CDKN1C), mRNA'
    if "PREDICTED" in taxa_splitnames[1].upper():
        taxa_splitnames = taxa_splitnames[1:]
    # end if

    # If hit is a phage sequence
    if taxa_splitnames[1] == "phage":
        # Assumming that the man who sortes by genus or species isn't interested in phage strain name
        if sens == "genus" or sens == "species":
            return '_'.join( [taxa_splitnames[0], taxa_splitnames[1]] ) # return "<Host_name> phage"
        else:
            return taxa_name.replace(' ', '_')   # return full name if we sort by strain
        # end if
    # end if

    # E.g. 'Bacterium clone zdt-9n2'
    if "clone" in taxa_splitnames:
        return taxa_name.replace(' ', '_')   # return full name
    # end if

    # If someone has shortened genus name
    if '.' in taxa_splitnames[0] or '.' in taxa_splitnames[1]:

        if sens != "strain":
            # 'E. coli'
            if not re_search(r"^[A-Z]\.$", taxa_splitnames[0]) is None:
                return '_'.join( [taxa_splitnames[0], taxa_splitnames[1]] ) # return genus and species
            # 'E.coli' (without space)
            elif not re_search(r"^[A-Z]\.[a-z]+$", taxa_splitnames[0]) is None:
                return taxa_splitnames[0] # 'E.coli' will be returned
        else:
            return taxa_name.replace(' ', '_')   # return full name
        # end if
    # end if 

    if sens == "genus":
        return taxa_splitnames[0] # return genus
    
    elif sens == "species":
        # if species is not specified
        if taxa_splitnames[1] == "sp.":
            return taxa_name.replace(' ', '_')   # return full name
        else:
            return '_'.join( [taxa_splitnames[0], taxa_splitnames[1]] ) # return genus and species
        # end if
    elif sens == "strain":
        return taxa_name.replace(' ', '_')   # return full name
    # end if

    # Execution should not reach here
    raise Exception("Taxonomy name formatting error!")
# end def format_taxonomy_name


def read_fastq_record(read_file, fmt_func):
    """
    :param read_file: file instance of FASTQ file to retrieve sequences from;
    :type fasta_file: _io.TextIOWrapper or gzip.GzipFile;
    :param fmt_func: function from 'FORMATTING_FUNCS' tuple;

    Returns dictionary of the following structure:
    {
        "seq_id": ID_of_sequence,
        "seq": sequence_itself,
        "opt_id": the_third_line,
        "qual_line": quality_line
    }
    """

    # Read 4 lines of fastq-record
    fastq_rec = {
        "seq_id": fmt_func(read_file.readline()),
        "seq": fmt_func(read_file.readline()),
        "opt_id": fmt_func(read_file.readline()),
        "qual_line": fmt_func(read_file.readline())
    }

    return fastq_rec
# end def read_fastq_record

def read_fasta_record(fasta_file, fmt_func):
    """
    :param fasta_file: file instance of FASTA file to retrieve sequences from;
    :type fasta_file: _io.TextIOWrapper or gzip.GzipFile;
    :param fmt_func: function from 'FORMATTING_FUNCS' tuple;

    Returns dictionary of the following structure:
    {
        "seq_id": ID_of_sequence,
        "seq": sequence_itself
    }
    """

    global next_id_line
    line = fmt_func(fasta_file.readline())
    packet = ""

    stop = False
    if not next_id_line is None:
        packet += next_id_line
    # end if
    packet += line

    while not stop:
        line = fmt_func(fasta_file.readline())
        if line.startswith('>'):
            stop = True
        # end if
        if line == "":
            break
        # end if
        packet += line
    # end while

    if line != "":
        next_id_line = packet.splitlines()[-1]+'\n'
        packet = '\n'.join(packet.splitlines()[:-1])
    else:
        next_id_line = None
        packet = packet.strip()
    # end if

    fasta_rec = {                    #read all 2 lines of FASTA-record
        "seq_id": packet.splitlines()[0],
        "seq": '\n'.join( packet.splitlines()[1:] )+'\n'
    }

    return fasta_rec
# end def read_fasta_record


def write_fastq_record(sorted_file, fastq_record):
    """
    :param sorted_file: file, which data from fastq_record is written in
    :type sorted_file: _io.TextIOWrapper
    :param fastq_record: dict of 4 elements. Elements are four corresponding lines of FASTQ
    :type fastq_record: dict<str: str>
    """

    sorted_file.write(bytes(fastq_record["seq_id"], "utf-8"))
    sorted_file.write(bytes(fastq_record["seq"], "utf-8"))
    sorted_file.write(bytes(fastq_record["opt_id"], "utf-8"))
    sorted_file.write(bytes(fastq_record["qual_line"], "utf-8"))
# end def write_fastq_record


def write_fasta_record(sorted_file, fasta_record):
    """
    :param sorted_file: file, which data from fasta_record is written in
    :type sorted_file: _io.TextIOWrapper
    :param fasta_record: dict of 2 elements. Elements are four corresponding lines of FASTA
    :type fasta_record: dict<str: str>
    """

    sorted_file.write(bytes(fasta_record["seq_id"]+'\n', "utf-8"))
    sorted_file.write(bytes(fasta_record["seq"], "utf-8"))
# end def write_fasta_record


is_gzipped = lambda f: True if f.endswith(".gz") else False
OPEN_FUNCS = (open, open_as_gzip)

# Data from plain text and gzipped should be parsed in different way,
#   because data from .gz is read as 'bytes', not 'str'.
FORMATTING_FUNCS = (
    lambda line: line,   # format text line
    lambda line: line.decode("utf-8")  # format gzipped line
)


# |===== Create output directory =====|
if not os.path.exists(outdir_path):
    try:
        os.makedirs(outdir_path)
    except Exception as err:
        printl(err_fmt("unable to create output directory!"))
        printl( str(err) )
        platf_depend_exit(1)
    # end try
# end if


# |=== Function for configuring dictionary containing information generated by barapost.py ===|

def get_res_tsv_fpath(new_dpath):
    """
    Function returns current TSV file. Sorting will be performad according to this file.

    :param new_dpath: current result directory;
    :type new_dpath: str;
    """

    brpst_resfile_patt = r".+_result\.tsv$"

    is_similar_to_tsv_res = lambda f: True if not re_search(brpst_resfile_patt, f) is None else False

    if not os.path.exists(new_dpath):
        printl(err_fmt("directory '{}' does not exist!".format(new_dpath)))
        printl(""" Please make sure you have performed taxonomic annotation of the following file
    '{}...'
    with 'prober.py' 'barapost.py'""".format(os.path.basename(new_dpath)))
        printl("""Also this error might occur if you forget to specify result directory
    generated by 'prober.py' with '-r' option.""")
        platf_depend_exit(0)
    # end if

    # Recent file will be the first in sorted list
    tsv_res_fpath = list( filter(is_similar_to_tsv_res, sorted(os.listdir(new_dpath))) )[0]

    return os.path.join(new_dpath, tsv_res_fpath)
# end def get_res_tsv_fpath


def update_file_dict(srt_file_dict, new_fpath):
    if new_fpath not in srt_file_dict.keys():
        try:
            srt_file_dict[intern(new_fpath)] = open_as_gzip(new_fpath, 'wb')
        except OSError as oserr:
            printl(err_fmt("error while opening one of result files"))
            printl("Errorneous file: '{}'".format(new_fpath))
            printl( str(oserr) )
            platf_depend_exit(1)
        # end try
    # end def
    return srt_file_dict
# end def update_file_dict


class SeqLength:
    """
    Class contains the only one field -- length of a sequence.
    This class is necessary because:
        1) length filtering is disabled by default;
        2) it is useful to create the length-comparing interface that will
            always tell that the sequence is long enough to keep it
            if length filtering is disabled;
    """

    def __init__(self, init_len):
        """
        :param init_len: length value to initialize
        :type init_len: int;
        """
        self.value = init_len
    # end def __init__

    def __lt__(self, rcmp_len):
        """
        "Less than" (<) dunder method.
        It will always return False if length filtering is disabled
            (i.e. if the rigth operand is None).
        :param rcmp_len: the rigth operand of '<' operator;
        :type rcmp_len: int or None;
        """
        if not rcmp_len is None:
            return self.value < rcmp_len
        else:
            return False
        # end if
    # end def __lt__

# end class seq_length


def sort_fastqa_file(fq_fa_path):
    """
    Function for sorting FASTQ and FASTA files.
    It stays separately from analoguous code from the kernel loop because
        interaction with HDF5 files and plain text ones have rather different interfases.
    It would be an ad hoc trick to implement a context manager wrapping for HDF5 files
        in order only to create an interface that would look like plain text files' one.

    :param fq_fa_path: path to FASTA (of FASTA) file meant to be processed;
    :type fq_fa_path: str;
    """

    global seqs_pass
    global seqs_fail
    global srt_file_dict

    new_dpath = get_curr_res_dir(fq_fa_path, tax_annot_res_dir)
    tsv_res_fpath = get_res_tsv_fpath(new_dpath)
    resfile_lines = configure_resfile_lines(tsv_res_fpath)

    how_to_open = OPEN_FUNCS[ is_gzipped(fq_fa_path) ] # get ready to open gzipped files
    if is_fastq(fq_fa_path):
        num_reads = int (sum(1 for line in how_to_open(fq_fa_path)) / LINES_PER_READ_FASTQ) # count number of reads in file
    else:
        num_reads = sum(1 if line[0] == '>' else 0 for line in how_to_open(fq_fa_path))
    # end if

    # Configure path to trash file
    if is_fastq(fq_fa_path):
        trash_fpath = os.path.join(outdir_path, "qual_less_Q{}{}.fastq.gz".format(int(min_ph33_qual),
            minlen_fmt_str))
    else:
        trash_fpath = os.path.join(outdir_path, "len_less_{}.fasta.gz".format(min_qlen))
    # end if

    # Get function that will read one record -- FASTQ or FASTA, in dependence of your file
    read_fun = read_fastq_record if is_fastq(fq_fa_path) else read_fasta_record
    # Get function that will write one record -- FASTQ or FASTA, in dependence of your file
    write_fun = write_fastq_record if is_fastq(fq_fa_path) else write_fasta_record
    
    with how_to_open(fq_fa_path) as source_fastq_file:

        fmt_func = FORMATTING_FUNCS[ is_gzipped(fq_fa_path) ]

        for i in range(num_reads):

            fastq_rec = read_fun(source_fastq_file, fmt_func) # get FASTQ or FASTA record
            read_name = intern(fmt_read_id(fastq_rec["seq_id"])) # get ID of the sequence

            try:
                hit_name, ph33_qual, q_len = resfile_lines[read_name] # find hit corresponding to this sequence
            except KeyError:
                printl(err_fmt("""read '{}' not found in TSV file containing taxonomic annotation.
  This TSV file: '{}'""".format(read_name, tsv_res_fpath)))
                printl("Make sure that this read has been already processed by 'prober.py' and 'barapost.py'.")
                platf_depend_exit(1)
            # If read is found in TSV file:
            else:
                q_len = SeqLength(q_len)
                if q_len < min_qlen or (ph33_qual != '-' and ph33_qual < min_ph33_qual):
                    # Place this sequence to trash file
                    srt_file_dict = update_file_dict(srt_file_dict, trash_fpath)
                    write_fun(srt_file_dict[trash_fpath], fastq_rec) # write current read to sorted file
                    seqs_fail += 1
                else:
                    # Get name of result FASTQ file to write this read in
                    sorted_file_path = os.path.join(outdir_path, "{}.fast{}.gz".format(hit_name,
                        'q' if is_fastq(fq_fa_path) else 'a'))
                    srt_file_dict = update_file_dict(srt_file_dict, sorted_file_path)
                    write_fun(srt_file_dict[sorted_file_path], fastq_rec) # write current read to sorted file
                    seqs_pass += 1
                # end if
            # end try

            printn("\r{} - {}/{} reads are sorted  ".format(get_work_time(), i+1, num_reads))
        # end for
        print() # print space to console but not to log file
        logfile.write("\r{} - {}/{} reads are sorted\n".format(get_work_time(), i+1, num_reads))
        printl('-'*20)
    # end with

# end def sort_fastqa_file


ont_read_signature = r"([0-9a-zA-Z\-]{20,})"

def fmt_read_id(read_id):

    srch_ont_read = re_search(ont_read_signature, read_id)
    if srch_ont_read is None:
        return read_id.partition(' ')[0].replace('>', '')
    else:
        return srch_ont_read.group(1)
# end def fmt_read_id


# If FAST5-untwisting is enabled, we need to import 'shelve' and define two functions.
# And we do not need it otherwise.
if untwist_fast5:

    from shelve import open as open_shelve

    # Names of index files
    index_name = "fast5_to_tsvtaxann_idx"

    # Create index directory
    index_dirpath = os.path.join(tax_annot_res_dir, index_name) # name of directory that will contain indicies
    if not os.path.isdir(index_dirpath):
        try:
            os.makedirs(index_dirpath)
        except OSError as oserr:
            printl(err_fmt("cannot create index directory"))
            printl("Directory that cannot be created: '{}'".format(index_dirpath))
            printl("Reason: '{}'".format( str(oserr) ))
            platf_depend_exit(1)
        # end try
    # end if

    use_old_index = False

    if len(os.listdir(index_dirpath)) != 0:
        printl("Attention! Index file created by '-u' (--untwist_fast5) option exists (left from previous run).")

        error = True

        while error:
            reply = input("""  Press ENTER to make new index file
  or enter 'u' to use old index file:>>""")
            if reply == "":
                error = False
            elif reply == 'u':
                use_old_index = True
                error = False
            else:
                print("Invalid reply!\n")
            # end if
        # end while
        printl("You have chosen to {} index file.\n".format("use old" if use_old_index else "make new"))
    # end if

    # We do not need this function if we do not make new index
    if not use_old_index:
        def map_f5reads_2_taxann(QA5_list):
            """
            Function perform mapping of all reads stored in input FAST5 files
                to existing TSV files containing taxonomic annotation info.

            It creates an index DBM file.

            Generally speaking, reads from one FAST5 are spread between several
            FASTQ (and hence, TSV-taxann) files.
            Structure of our index allows to minimize times needed to read plain
            (i.e. sequential access) TSV files.
            Well, structure of our index is following:

            <DBM file>:
            {
                <path_to_FAST5_1>: {
                                    <path_to_TSV_1.1>: [<read_ID_1.1.1>, <read_ID_1.1.2>, ..., <read_ID_1.1.N>],
                                    <path_to_TSV_1.2>: [<read_ID_1.2.1>, <read_ID_1.2.2>, ..., <read_ID_1.2.N>],
                                    ...
                                    <path_to_TSV_1.M>: [<read_ID_1.M.1>, <read_ID_1.M.2>, ..., <read_ID_1.M.N>]
                                 },
                <path_to_FAST5_2>: {
                                    <path_to_TSV_1.1>: [<read_ID_1.1.1>, <read_ID_1.1.2>, ..., <read_ID_1.1.N>],
                                    <path_to_TSV_1.2>: [<read_ID_1.2.1>, <read_ID_1.2.2>, ..., <read_ID_1.2.N>],
                                    ...
                                    <path_to_TSV_2.M>: [<read_ID_2.M.1>, <read_ID_2.M.2>, ..., <read_ID_2.M.N>]
                                 },
                ...
                <path_to_FAST5_K>: {
                                    <path_to_TSV_K.1>: [<read_ID_K.1.1>, <read_ID_K.1.2>, ..., <read_ID_K.1.N>],
                                    <path_to_TSV_K.2>: [<read_ID_K.2.1>, <read_ID_K.2.2>, ..., <read_ID_K.2.N>],
                                    ...
                                    <path_to_TSV_K.M>: [<read_ID_K.M.1>, <read_ID_K.M.2>, ..., <read_ID_K.M.N>]
                                 },
            }
            """

            # Get list of paths to FAST5 files
            fast5_list = list(filter(lambda f: True if f.endswith(".fast5") else False, QA5_list))

            # Get all directories nested in 'tax_annot_res_dir'
            taxann_dir_lst = list(filter(lambda f: True if os.path.isdir(f) else False,
                glob( os.path.join(tax_annot_res_dir, "*") )))

            # Exclude "local_database" and "fast5_to_fastq_idx" from this list
            for dir_to_exclude in (index_name, "local_database"):
                ldb_dir_path = os.path.join(tax_annot_res_dir, dir_to_exclude)
                if ldb_dir_path in taxann_dir_lst:
                    taxann_dir_lst.remove(ldb_dir_path)
                # end if
            # end for

            # Get path to TSV files containing taxonomy annotation info
            tsv_taxann_lst = list()
            for taxann_dir in taxann_dir_lst:
                putative_tsvs = glob("{}{}*.tsv".format(taxann_dir, os.sep))
                if len(putative_tsvs) == 1:
                    tsv_taxann_lst.append(putative_tsvs[0])
                elif len(putative_tsvs) == 0:
                    printl("""Warning!  There is no taxonomic annotation info in the following directory:
      '{}'
    Omitting this directory.\n""".format(taxann_dir))
                else:
                    printl("""Warning!  Multiple TSV files in the following directory:
      '{}'
    Please, remove extra files and leave only one, which contains actual taxononic annotation info.""".format(taxann_dir))
                    platf_depend_exit(1)
                # end if
            # end for
            del taxann_dir_lst

            printl("{} - Untwisting started.".format(get_work_time()))

            # Open index files overwriting existing data ('n' parameter)
            index_f5_2_tsv = open_shelve( os.path.join(index_dirpath, index_name), 'n' )

            # Iterate over FAST5 files
            for f5_path in fast5_list:

                printn("Untwisting reads in '{}'...".format(os.path.basename(f5_path)))

                f5_file = h5py.File(f5_path, 'r')# open FAST5 file
                readids_to_seek = list(f5_file.keys()) # list of not-found-yet read IDs
                idx_dict = dict() # dictionary for index

                # This saving is needed to compare with 'len(readids_to_seek)'
                #    after all TSV will be looked through in order to
                #    determine if some reads miss taxonomic annotation.
                len_before = len(readids_to_seek)

                # Iterate over TSV-taaxnn file
                for tsv_taxann_fpath in tsv_taxann_lst:

                    with open(tsv_taxann_fpath, 'r') as taxann_file:

                        # Get all read IDs in current TSV
                        readids_in_tsv = list( map(lambda l: l.split('\t')[0], taxann_file.readlines()) )

                        # Iterate over all other reads in current FAST5
                        #    ('reversed' is necessary because we remove items from list in this loop)
                        for readid in reversed(readids_to_seek):
                            if fmt_read_id(readid) in readids_in_tsv:
                                # If not first -- write data to dict (and to index later)
                                try:
                                    idx_dict[tsv_taxann_fpath].append(readid) # append to existing list
                                except KeyError:
                                    idx_dict[tsv_taxann_fpath] = [readid] # create a new list
                                finally:
                                    readids_to_seek.remove(readid)
                                # end try
                            # end if
                        # end for
                    # end with
                    if len(readids_to_seek) == 0:
                        break
                    # end if
                # end for

                # If after all TSV is checked but nothing have changed -- we miss taxonomic annotation
                #     for some reads! And we will write their IDs to 'missing_reads_lst.txt' file.
                if len(readids_to_seek) == len_before:
                    printl(err_fmt("reads from FAST5 file not found"))
                    printl("FAST5 file: '{}'".format(f5_path))
                    printl("Some reads reads have not undergone taxonomic annotation.")
                    missing_log = "missing_reads_lst.txt"
                    printl("List of missing reads are in following file:\n  '{}'\n".format(missing_log))
                    with open(missing_log, 'w') as missing_logfile:
                        missing_logfile.write("Missing reads from file '{}':\n\n".format(f5_path))
                        for readid in readids_to_seek:
                            missing_logfile.write(fmt_read_id(readid) + '\n')
                        # end for
                    # index_read2tsv.close()
                    index_f5_2_tsv.close()
                    from shutil import rmtree # in other cases this import is not necessary
                    try:
                        rmtree(index_dirpath)
                    except OSError as oserr:
                        printl("error while removing index directory: {}".format(oserr))
                    finally:
                        platf_depend_exit(3)
                    # end try
                # end if

                # Update index
                index_f5_2_tsv[f5_path] = idx_dict
                print("\rUntwisting reads in '{}'...{}".format(os.path.basename(f5_path), check_mark))
            # end for

            # index_read2tsv.close()
            index_f5_2_tsv.close()
            printl("{} - Untwisting is completed.".format(get_work_time()))
            printl('-'*20+'\n')
        # end def map_f5reads_2_taxann
    # end if


    def sort_fast5_file(f5_path):
        """
        Function sorts FAST5 file with untwisting.

        :param f5_path: path to FAST5 file meant to be processed;
        :type f5_path: str;
        """

        global seqs_pass
        global seqs_fail

        trash_fpath = os.path.join(outdir_path, "qual_less_Q{}{}.fast5".format(int(min_ph33_qual),
                minlen_fmt_str))

        from_f5 = h5py.File(f5_path, 'r') # open source FAST5
        num_reads = len(from_f5) # get number of reads in it

        try:
            readids_to_seek = list(from_f5.keys()) # list of not-sorted-yet read IDs
        except Exception as e:
            print(str(e))
            exit(0)
        # end try

        # Fill the list 'readids_to_seek'
        for read_name in from_f5:
            # Get rid of "read_"
            readids_to_seek.append(intern(read_name))
        # end for

        i = 0 # counter

        # Walk through the index
        index_f5_2_tsv = open_shelve( os.path.join(index_dirpath, index_name), 'r' )

        for tsv_path in index_f5_2_tsv[f5_path].keys():

            read_names = index_f5_2_tsv[f5_path][tsv_path]
            resfile_lines = configure_resfile_lines(tsv_path)

            for read_name in read_names:
                try:
                    hit_name, ph33_qual, q_len = resfile_lines[intern(fmt_read_id(read_name))]
                except KeyError:
                    printl(err_fmt("missing taxonomic annotation info for read '{}'".format(fmt_read_id(read_name))))
                    printl("It is stored in '{}' FAST5 file".format(f5_path))
                    printl("Try to make new index file (press ENTER on corresponding prompt).")
                    printl("""Or, if does not work for you, make sure that taxonomic annotation info
  for this read is present in one of TSV files generated by 'prober.py' and 'barapost.py'.""")
                    index_f5_2_tsv.close()
                    platf_depend_exit(1)
                else:
                    q_len = SeqLength(q_len)
                    if q_len < min_qlen or (ph33_qual != '-' and ph33_qual < min_ph33_qual):
                        # Get name of result FASTQ file to write this read in
                        copy_read_f5_2_f5(from_f5, read_name, trash_fpath)
                        seqs_fail += 1
                    else:
                        # Get name of result FASTQ file to write this read in
                        sorted_file_path = os.path.join(outdir_path, "{}.fast5".format(hit_name))
                        copy_read_f5_2_f5(from_f5, read_name, sorted_file_path)
                        seqs_pass += 1
                    # end if
                    i += 1
                    printn("\r{} - {}/{} reads are sorted  ".format(get_work_time(), i, num_reads))
                # end try
            # end for

        index_f5_2_tsv.close()
        print() # print blank line to console but not to log file
        logfile.write("\r{} - {}/{} reads are sorted\n".format(get_work_time(), i, num_reads))
        printl('-'*20)
    # end def sort_fast5_file

else: # if untwisting is not enabled, this function will be different

    def sort_fast5_file(f5_path):
        """
        Function sorts FAST5 file without untwisting.

        :param f5_path: path to FAST5 file meant to be processed;
        :type f5_path: str;
        """

        global seqs_pass
        global seqs_fail

        trash_fpath = os.path.join(outdir_path, "qual_less_Q{}{}.fast5".format(int(min_ph33_qual),
                minlen_fmt_str))

        new_dpath = glob("{}{}*{}*".format(tax_annot_res_dir, os.sep, get_checkstr(f5_path)))[0]
        tsv_res_fpath = get_res_tsv_fpath(new_dpath)
        resfile_lines = configure_resfile_lines(tsv_res_fpath)

        from_f5 = h5py.File(f5_path, 'r')
        num_reads = len(from_f5)

        for i, read_name in enumerate(from_f5):

            if not read_name.startswith("read_"):
                printl("Name of read '{}' from FAST5 file has format that is unforseen by the developer.".format(read_name))
                printl("Please, contact the developer.")
                platf_depend_exit(1)
            # end if

            try:
                hit_name, ph33_qual, q_len = resfile_lines[intern(fmt_read_id(read_name))] # omit 'read_' in the beginning of FAST5 group's name
            except KeyError:
                printl(err_fmt("""read '{}' not found in TSV file containing taxonomic annotation.
      This TSV file: '{}'""".format(fmt_read_id(read_name), tsv_res_fpath)))
                printl("Try running sorter with '-u' (--untwist-fast5') flag.\n")
                platf_depend_exit(1)
            # If read is found in TSV file:
            else:
                q_len = SeqLength(q_len)
                if ph33_qual != '-' and ph33_qual < min_ph33_qual:
                    # Get name of result FASTQ file to write this read in
                    copy_read_f5_2_f5(from_f5, read_name, trash_fpath)
                    seqs_fail += 1
                else:
                    # Get name of result FASTQ file to write this read in
                    sorted_file_path = os.path.join(outdir_path, "{}.fast5".format(hit_name))
                    copy_read_f5_2_f5(from_f5, read_name, sorted_file_path)
                    seqs_pass += 1
                # end if
            # end try
            printn("\r{} - {}/{} reads are sorted  ".format(get_work_time(), i+1, num_reads))
        # end for

        print() # print blank line to console but not to log file
        logfile.write("\r{} - {}/{} reads are sorted\n".format(get_work_time(), i+1, num_reads))
        printl('-'*20)
    # end def sort_fast5_file
# end if

def configure_resfile_lines(tsv_res_fpath):
    """
    Function returns dictionary, where keys are sequence (i.e. sequences meant to be sorted) IDs,
        and values are corresponding hit names.

    :param tsv_res_fpath: path to current TSV file. Sorting will be performed accorfing to this TSV file;
    :type tsv_res_fpath: str;
    """

    resfile_lines = dict()

    with open(tsv_res_fpath, 'r') as brpst_resfile:

        brpst_resfile.readline() # pass the head of the table
        line = brpst_resfile.readline().strip() # get the first informative line

        while line != "":
            splt = line.split('\t')
            read_name = intern(splt[0])
            hit_name = splt[1]
            try:
                query_len = int(splt[3])  # we will filter by length
            except ValueError as verr:
                printl(err_fmt("query length parsing error"))
                printl( str(verr) )
                printl("Please, contact the developer.")
                platf_depend_exit(1)
            # end try
            try:
                phred33 = float(splt[8]) # we will filter by quality
            except ValueError as verr:
                if splt[8] == '-':
                    # Keep minus as quality if there is no quality information.
                    # Error will not be raised.
                    phred33 = splt[8]
                else:
                    printl(err_fmt("query quality parsing error"))
                    printl( str(verr) )
                    printl("Please, contact the developer.")
                    platf_depend_exit(1)
                # end if
            # end try
            resfile_lines[read_name] = [hit_name, phred33, query_len]
            line = brpst_resfile.readline().strip() # get next line
        # end while
    # end with

    # |===== Format taxonomy names =====|
    for read_name in resfile_lines.keys():
        resfile_lines[read_name][0] = format_taxonomy_name(resfile_lines[read_name][0], sens)
    # end for

    return resfile_lines
# end def configure_resfile_lines


# |===== Proceed =====|

logfile.write('\n')
printl( get_work_time() + " ({}) ".format(strftime("%Y.%m.%d %H:%M:%S", localtime(start_time))) + "- Start working\n")

printl(" - Sorting sensitivity: '{}';".format(sens))
printl(" - Minimum mean Phred33 quality of a read to keep: {};".format(min_ph33_qual))
printl(" - Minimum length of a read to keep: {};".format(min_qlen if not min_qlen is None else "unlimited"))
if untwist_fast5:
    printl(" - \"FAST5 untwisting\" is enabled.")
# end if
print()

printl("\nFollowing files will be processed:")
for i, path in enumerate(QA5_list):
    printl("  {}. {}".format(i+1, path))
# end for
printl('-'*20 + '\n')


LINES_PER_READ_FASTQ = 4
is_fastq = lambda f: True if not re_search(r".*\.fastq(\.gz)?$", f) is None else False
num_files = len(QA5_list)
next_id_line = None
srt_file_dict = dict()

seqs_pass, seqs_fail = 0, 0
minlen_fmt_str = "_len_less_{}".format(min_qlen) if not min_qlen is None else ""

if untwist_fast5 and not use_old_index:
    map_f5reads_2_taxann(QA5_list)
# end if

for j, fq_fa_path in enumerate(QA5_list):

    printl("{} - '{}': start sorting".format(get_work_time(), os.path.basename(fq_fa_path)))

    # Interface of interactiong with HDF5 files are quite different from plain text ones.
    # So it is beter to write a separate function for them.
    if not fq_fa_path.endswith(".fast5"):
        sort_fastqa_file(fq_fa_path)
    else:
        sort_fast5_file(fq_fa_path)
    # end if
# end for

# Close all sorted files
for file_obj in srt_file_dict.values():
    file_obj.close()
# end for

def get_undr_sep_number(number):
    undr_sep_num = str(number)
    for i in range(len(undr_sep_num)-4, -1, -4):
        undr_sep_num = undr_sep_num[: i+1] + '_' + undr_sep_num[i+1: ]
    # end for
    return undr_sep_num
# end def get_undr_sep_number

printl("\n{} sequences have been processed.".format(get_undr_sep_number(seqs_pass + seqs_fail)))
if seqs_fail > 0:
    len_fmt_str = " and length ({} bp)".format(min_qlen) if not min_qlen is None else ""
    printl("{} of them have passed quality (Q{}){} controle.".format(get_undr_sep_number(seqs_pass),
        int(min_ph33_qual), len_fmt_str))
# end if

end_time = time()
printl( '\n'+get_work_time() + " ({}) ".format(strftime("%Y.%m.%d %H:%M:%S", localtime(end_time))) + "- Sorting is completed!\n")
platf_depend_exit(0)